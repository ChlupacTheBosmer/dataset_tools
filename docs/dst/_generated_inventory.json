{
  "api": [
    {
      "module": "src.dataset_tools",
      "file": "src/dataset_tools/__init__.py",
      "doc": "Public exports for the dataset_tools package.",
      "classes": [],
      "functions": []
    },
    {
      "module": "src.dataset_tools.anomaly",
      "file": "src/dataset_tools/anomaly/__init__.py",
      "doc": "Package initializer for `dataset_tools.anomaly`.",
      "classes": [],
      "functions": []
    },
    {
      "module": "src.dataset_tools.anomaly.anomalib",
      "file": "src/dataset_tools/anomaly/anomalib.py",
      "doc": "Implementation module for anomaly analysis.",
      "classes": [
        {
          "name": "PreparedAnomalibDataset",
          "lineno": 24,
          "doc": "PreparedAnomalibDataset used by anomaly analysis.\n    ",
          "methods": [
            {
              "name": "to_dict",
              "signature": "(self) -> dict[str, Any]",
              "lineno": 40,
              "doc": "Perform to dict.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n        "
            }
          ]
        },
        {
          "name": "AnomalibArtifact",
          "lineno": 63,
          "doc": "AnomalibArtifact used by anomaly analysis.\n    ",
          "methods": [
            {
              "name": "to_dict",
              "signature": "(self) -> dict[str, Any]",
              "lineno": 75,
              "doc": "Perform to dict.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n        "
            },
            {
              "name": "from_dict",
              "signature": "(payload: dict[str, Any]) -> 'AnomalibArtifact'",
              "lineno": 93,
              "doc": "Perform from dict.\n\nArgs:\n    payload: JSON-like payload consumed by this routine.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n        "
            }
          ]
        }
      ],
      "functions": [
        {
          "name": "_load_dataset",
          "signature": "(dataset_name: str)",
          "lineno": 139,
          "doc": "Load dataset required by this module.\n\nArgs:\n    dataset_name: Name of the FiftyOne dataset to operate on.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n    "
        },
        {
          "name": "_resolve_view",
          "signature": "(dataset, tag_filter: str | None)",
          "lineno": 153,
          "doc": "Resolve view from provided inputs.\n\nArgs:\n    dataset: FiftyOne dataset or dataset-like collection used by this operation.\n    tag_filter: Sample tag filter used to restrict processing scope.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n    "
        },
        {
          "name": "_safe_name",
          "signature": "(value: str) -> str",
          "lineno": 168,
          "doc": "Internal helper for safe name.\n\nArgs:\n    value: Input value to normalize or validate.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n    "
        },
        {
          "name": "_clear_dir",
          "signature": "(path: Path, overwrite: bool)",
          "lineno": 181,
          "doc": "Internal helper for clear dir.\n\nArgs:\n    path: Filesystem path used for reading/writing artifacts.\n    overwrite: Whether existing resources should be replaced.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n    "
        },
        {
          "name": "_link_or_copy",
          "signature": "(src: Path, dst: Path, *, symlink: bool)",
          "lineno": 201,
          "doc": "Internal helper for link or copy.\n\nArgs:\n    src: Value controlling src for this routine.\n    dst: Value controlling dst for this routine.\n    symlink: Value controlling symlink for this routine.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n    "
        },
        {
          "name": "_sample_target_name",
          "signature": "(sample_id: str, filepath: str) -> str",
          "lineno": 221,
          "doc": "Internal helper for sample target name.\n\nArgs:\n    sample_id: Value controlling sample id for this routine.\n    filepath: Filesystem path to a file.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n    "
        },
        {
          "name": "_extract_mask_path",
          "signature": "(sample: Any, mask_field: str) -> str | None",
          "lineno": 237,
          "doc": "Internal helper for extract mask path.\n\nArgs:\n    sample: Value controlling sample for this routine.\n    mask_field: Field containing segmentation masks or anomaly masks.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n    "
        },
        {
          "name": "prepare_anomalib_folder_dataset",
          "signature": "(dataset_name: str, *, output_root: str | Path, normal_tag: str | None = None, abnormal_tag: str | None = None, mask_field: str | None = None, symlink: bool = True, overwrite_data: bool = False) -> PreparedAnomalibDataset",
          "lineno": 269,
          "doc": "Perform prepare anomalib folder dataset.\n\nArgs:\n    dataset_name: Name of the FiftyOne dataset to operate on.\n    output_root: Value controlling output root for this routine.\n    normal_tag: Tag identifying normal samples.\n    abnormal_tag: Tag identifying abnormal samples.\n    mask_field: Field containing segmentation masks or anomaly masks.\n    symlink: Value controlling symlink for this routine.\n    overwrite_data: Value controlling overwrite data for this routine.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n    "
        },
        {
          "name": "_import_anomalib_components",
          "signature": "()",
          "lineno": 364,
          "doc": "Internal helper for import anomalib components.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n    "
        },
        {
          "name": "_parse_image_size",
          "signature": "(value: str | None) -> tuple[int, int] | None",
          "lineno": 382,
          "doc": "Parse and validate image size input values.\n\nArgs:\n    value: Input value to normalize or validate.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n    "
        },
        {
          "name": "_create_datamodule",
          "signature": "(prepared: PreparedAnomalibDataset, *, datamodule_name: str, image_size: tuple[int, int] | None = None, train_batch_size: int = 8, eval_batch_size: int = 8, num_workers: int = 0, normal_split_ratio: float = 0.2, test_split_mode: str = 'from_dir', test_split_ratio: float = 0.2, val_split_mode: str = 'same_as_test', val_split_ratio: float = 0.5, seed: int | None = None)",
          "lineno": 403,
          "doc": "Internal helper for create datamodule.\n\nArgs:\n    prepared: Value controlling prepared for this routine.\n    datamodule_name: Value controlling datamodule name for this routine.\n    image_size: Value controlling image size for this routine.\n    train_batch_size: Batch size used during training.\n    eval_batch_size: Batch size used during evaluation/inference.\n    num_workers: Worker count used by data loading operations.\n    normal_split_ratio: Value controlling normal split ratio for this routine.\n    test_split_mode: Value controlling test split mode for this routine.\n    test_split_ratio: Value controlling test split ratio for this routine.\n    val_split_mode: Value controlling val split mode for this routine.\n    val_split_ratio: Value controlling val split ratio for this routine.\n    seed: Value controlling seed for this routine.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n    "
        },
        {
          "name": "save_anomalib_artifact",
          "signature": "(path: str | Path, artifact: AnomalibArtifact)",
          "lineno": 469,
          "doc": "Save anomalib artifact to persistent storage.\n\nArgs:\n    path: Filesystem path used for reading/writing artifacts.\n    artifact: Anomaly artifact path or descriptor.\n\nReturns:\n    None or lightweight metadata about the persisted artifact.\n    "
        },
        {
          "name": "load_anomalib_artifact",
          "signature": "(path: str | Path) -> AnomalibArtifact",
          "lineno": 485,
          "doc": "Load anomalib artifact required by this module.\n\nArgs:\n    path: Filesystem path used for reading/writing artifacts.\n\nReturns:\n    Loaded object/data required by downstream workflow steps.\n    "
        },
        {
          "name": "train_and_export_anomalib",
          "signature": "(dataset_name: str, *, model_ref: str = 'anomalib:padim', normal_tag: str | None = None, abnormal_tag: str | None = None, mask_field: str | None = None, artifact_dir: str | Path | None = None, data_dir: str | Path | None = None, artifact_format: str = 'openvino', image_size: str | None = None, train_batch_size: int = 8, eval_batch_size: int = 8, num_workers: int = 0, normal_split_ratio: float = 0.2, test_split_mode: str = 'from_dir', test_split_ratio: float = 0.2, val_split_mode: str = 'same_as_test', val_split_ratio: float = 0.5, seed: int | None = None, max_epochs: int | None = None, accelerator: str | None = None, devices: str | int | None = None, symlink: bool = True, overwrite_data: bool = False, artifact_json: str | Path | None = None) -> AnomalibArtifact",
          "lineno": 500,
          "doc": "Perform train and export anomalib.\n\nArgs:\n    dataset_name: Name of the FiftyOne dataset to operate on.\n    model_ref: Provider-qualified model reference (for example `hf:...`, `foz:...`, `anomalib:...`).\n    normal_tag: Tag identifying normal samples.\n    abnormal_tag: Tag identifying abnormal samples.\n    mask_field: Field containing segmentation masks or anomaly masks.\n    artifact_dir: Value controlling artifact dir for this routine.\n    data_dir: Value controlling data dir for this routine.\n    artifact_format: Artifact runtime format (`openvino` or `torch`).\n    image_size: Value controlling image size for this routine.\n    train_batch_size: Batch size used during training.\n    eval_batch_size: Batch size used during evaluation/inference.\n    num_workers: Worker count used by data loading operations.\n    normal_split_ratio: Value controlling normal split ratio for this routine.\n    test_split_mode: Value controlling test split mode for this routine.\n    test_split_ratio: Value controlling test split ratio for this routine.\n    val_split_mode: Value controlling val split mode for this routine.\n    val_split_ratio: Value controlling val split ratio for this routine.\n    seed: Value controlling seed for this routine.\n    max_epochs: Value controlling max epochs for this routine.\n    accelerator: Value controlling accelerator for this routine.\n    devices: Device selection passed through to underlying runtime.\n    symlink: Value controlling symlink for this routine.\n    overwrite_data: Value controlling overwrite data for this routine.\n    artifact_json: Value controlling artifact json for this routine.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n    "
        },
        {
          "name": "_extract_prediction_fields",
          "signature": "(prediction: Any) -> tuple[float, bool, np.ndarray | None, np.ndarray | None]",
          "lineno": 684,
          "doc": "Internal helper for extract prediction fields.\n\nArgs:\n    prediction: Value controlling prediction for this routine.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n    "
        },
        {
          "name": "_to_numpy",
          "signature": "(value: Any) -> np.ndarray",
          "lineno": 744,
          "doc": "Internal helper for to numpy.\n\nArgs:\n    value: Input value to normalize or validate.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n    "
        },
        {
          "name": "_assert_trusted_torch_loading",
          "signature": "(trust_remote_code: bool)",
          "lineno": 772,
          "doc": "Internal helper for assert trusted torch loading.\n\nArgs:\n    trust_remote_code: Value controlling trust remote code for this routine.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n    "
        },
        {
          "name": "_infer_export_type",
          "signature": "(path: Path) -> str",
          "lineno": 795,
          "doc": "Internal helper for infer export type.\n\nArgs:\n    path: Filesystem path used for reading/writing artifacts.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n    "
        },
        {
          "name": "_resolve_anomalib_artifact",
          "signature": "(artifact: str | Path, *, artifact_format: str | None = None) -> AnomalibArtifact",
          "lineno": 815,
          "doc": "Resolve anomalib artifact from provided inputs.\n\nArgs:\n    artifact: Anomaly artifact path or descriptor.\n    artifact_format: Artifact runtime format (`openvino` or `torch`).\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n    "
        },
        {
          "name": "_build_inferencer",
          "signature": "(artifact: AnomalibArtifact, *, device: str | None = None, trust_remote_code: bool = False)",
          "lineno": 847,
          "doc": "Build inferencer for downstream steps.\n\nArgs:\n    artifact: Anomaly artifact path or descriptor.\n    device: Runtime device selection for inference/training.\n    trust_remote_code: Value controlling trust remote code for this routine.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n    "
        },
        {
          "name": "_score_with_engine_predict",
          "signature": "(*, artifact: AnomalibArtifact, sample_ids: list[str], filepaths: list[str], threshold: float, device: str | None, trust_remote_code: bool) -> tuple[dict[str, float], dict[str, bool], dict[str, np.ndarray], dict[str, np.ndarray]]",
          "lineno": 883,
          "doc": "Internal helper for score with engine predict.\n\nArgs:\n    artifact: Anomaly artifact path or descriptor.\n    sample_ids: Value controlling sample ids for this routine.\n    filepaths: Value controlling filepaths for this routine.\n    threshold: Decision/filter threshold used by this operation.\n    device: Runtime device selection for inference/training.\n    trust_remote_code: Value controlling trust remote code for this routine.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n    "
        },
        {
          "name": "score_with_anomalib_artifact",
          "signature": "(dataset_name: str, *, artifact: str | Path, artifact_format: str | None = None, threshold: float = 0.5, score_field: str = 'anomaly_score', flag_field: str = 'is_anomaly', label_field: str | None = None, map_field: str | None = None, mask_field: str | None = None, tag_filter: str | None = None, device: str | None = None, trust_remote_code: bool = False) -> dict[str, Any]",
          "lineno": 989,
          "doc": "Perform score with anomalib artifact.\n\nArgs:\n    dataset_name: Name of the FiftyOne dataset to operate on.\n    artifact: Anomaly artifact path or descriptor.\n    artifact_format: Artifact runtime format (`openvino` or `torch`).\n    threshold: Decision/filter threshold used by this operation.\n    score_field: Sample field name where numeric scores are written.\n    flag_field: Sample field name where boolean flags are written.\n    label_field: Field name containing labels for this operation.\n    map_field: Value controlling map field for this routine.\n    mask_field: Field containing segmentation masks or anomaly masks.\n    tag_filter: Sample tag filter used to restrict processing scope.\n    device: Runtime device selection for inference/training.\n    trust_remote_code: Value controlling trust remote code for this routine.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n    "
        }
      ]
    },
    {
      "module": "src.dataset_tools.anomaly.base",
      "file": "src/dataset_tools/anomaly/base.py",
      "doc": "Implementation module for anomaly analysis.",
      "classes": [
        {
          "name": "AnomalyReference",
          "lineno": 10,
          "doc": "AnomalyReference used by anomaly analysis.\n    ",
          "methods": [
            {
              "name": "to_dict",
              "signature": "(self) -> dict[str, Any]",
              "lineno": 19,
              "doc": "Perform to dict.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n        "
            },
            {
              "name": "from_dict",
              "signature": "(payload: dict[str, Any]) -> 'AnomalyReference'",
              "lineno": 34,
              "doc": "Perform from dict.\n\nArgs:\n    payload: JSON-like payload consumed by this routine.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n        "
            }
          ]
        }
      ],
      "functions": []
    },
    {
      "module": "src.dataset_tools.anomaly.pipeline",
      "file": "src/dataset_tools/anomaly/pipeline.py",
      "doc": "Implementation module for anomaly analysis.",
      "classes": [],
      "functions": [
        {
          "name": "_load_dataset",
          "signature": "(dataset_name: str)",
          "lineno": 17,
          "doc": "Load dataset required by this module.\n\nArgs:\n    dataset_name: Name of the FiftyOne dataset to operate on.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n    "
        },
        {
          "name": "_resolve_view",
          "signature": "(dataset, tag_filter: str | None)",
          "lineno": 31,
          "doc": "Resolve view from provided inputs.\n\nArgs:\n    dataset: FiftyOne dataset or dataset-like collection used by this operation.\n    tag_filter: Sample tag filter used to restrict processing scope.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n    "
        },
        {
          "name": "_read_embeddings",
          "signature": "(view, embeddings_field: str) -> tuple[list[str], list[np.ndarray]]",
          "lineno": 46,
          "doc": "Internal helper for read embeddings.\n\nArgs:\n    view: FiftyOne view selecting the sample subset to process.\n    embeddings_field: Field containing embeddings vectors.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n    "
        },
        {
          "name": "fit_embedding_distance_reference",
          "signature": "(dataset_name: str, *, embeddings_field: str = 'embeddings', normal_tag: str | None = None, threshold: float | None = None, threshold_quantile: float = 0.95) -> AnomalyReference",
          "lineno": 71,
          "doc": "Perform fit embedding distance reference.\n\nArgs:\n    dataset_name: Name of the FiftyOne dataset to operate on.\n    embeddings_field: Field containing embeddings vectors.\n    normal_tag: Tag identifying normal samples.\n    threshold: Decision/filter threshold used by this operation.\n    threshold_quantile: Quantile used to infer a threshold when explicit threshold is omitted.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n    "
        },
        {
          "name": "score_with_embedding_distance",
          "signature": "(dataset_name: str, *, reference: AnomalyReference, score_field: str = 'anomaly_score', flag_field: str = 'is_anomaly', tag_filter: str | None = None) -> dict[str, Any]",
          "lineno": 119,
          "doc": "Perform score with embedding distance.\n\nArgs:\n    dataset_name: Name of the FiftyOne dataset to operate on.\n    reference: Precomputed reference object used for scoring.\n    score_field: Sample field name where numeric scores are written.\n    flag_field: Sample field name where boolean flags are written.\n    tag_filter: Sample tag filter used to restrict processing scope.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n    "
        },
        {
          "name": "score_with_anomalib",
          "signature": "(dataset_name: str, *, artifact_path: str, artifact_format: str | None = None, threshold: float = 0.5, score_field: str = 'anomaly_score', flag_field: str = 'is_anomaly', label_field: str | None = None, map_field: str | None = None, mask_field: str | None = None, tag_filter: str | None = None, device: str | None = None, trust_remote_code: bool = False) -> dict[str, Any]",
          "lineno": 175,
          "doc": "Perform score with anomalib.\n\nArgs:\n    dataset_name: Name of the FiftyOne dataset to operate on.\n    artifact_path: Path to anomaly artifact metadata or model file.\n    artifact_format: Artifact runtime format (`openvino` or `torch`).\n    threshold: Decision/filter threshold used by this operation.\n    score_field: Sample field name where numeric scores are written.\n    flag_field: Sample field name where boolean flags are written.\n    label_field: Field name containing labels for this operation.\n    map_field: Value controlling map field for this routine.\n    mask_field: Field containing segmentation masks or anomaly masks.\n    tag_filter: Sample tag filter used to restrict processing scope.\n    device: Runtime device selection for inference/training.\n    trust_remote_code: Value controlling trust remote code for this routine.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n    "
        },
        {
          "name": "save_reference",
          "signature": "(path: str | Path, reference: AnomalyReference)",
          "lineno": 225,
          "doc": "Save reference to persistent storage.\n\nArgs:\n    path: Filesystem path used for reading/writing artifacts.\n    reference: Precomputed reference object used for scoring.\n\nReturns:\n    None or lightweight metadata about the persisted artifact.\n    "
        },
        {
          "name": "load_reference",
          "signature": "(path: str | Path) -> AnomalyReference",
          "lineno": 241,
          "doc": "Load reference required by this module.\n\nArgs:\n    path: Filesystem path used for reading/writing artifacts.\n\nReturns:\n    Loaded object/data required by downstream workflow steps.\n    "
        },
        {
          "name": "run_embedding_distance",
          "signature": "(dataset_name: str, *, embeddings_field: str = 'embeddings', normal_tag: str | None = None, score_tag: str | None = None, score_field: str = 'anomaly_score', flag_field: str = 'is_anomaly', threshold: float | None = None, threshold_quantile: float = 0.95, reference_path: str | None = None) -> dict[str, Any]",
          "lineno": 256,
          "doc": "Run embedding distance and return execution results.\n\nArgs:\n    dataset_name: Name of the FiftyOne dataset to operate on.\n    embeddings_field: Field containing embeddings vectors.\n    normal_tag: Tag identifying normal samples.\n    score_tag: Value controlling score tag for this routine.\n    score_field: Sample field name where numeric scores are written.\n    flag_field: Sample field name where boolean flags are written.\n    threshold: Decision/filter threshold used by this operation.\n    threshold_quantile: Quantile used to infer a threshold when explicit threshold is omitted.\n    reference_path: Path to a serialized reference object.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n    "
        }
      ]
    },
    {
      "module": "src.dataset_tools.brain",
      "file": "src/dataset_tools/brain/__init__.py",
      "doc": "Package initializer for `dataset_tools.brain`.",
      "classes": [],
      "functions": []
    },
    {
      "module": "src.dataset_tools.brain.base",
      "file": "src/dataset_tools/brain/base.py",
      "doc": "Implementation module for FiftyOne Brain analysis.",
      "classes": [
        {
          "name": "BrainOperation",
          "lineno": 11,
          "doc": "Operation class used in FiftyOne Brain analysis.\n    ",
          "methods": [
            {
              "name": "__init__",
              "signature": "(self, dataset_name: str, brain_key: str | None = None)",
              "lineno": 15,
              "doc": "Initialize `BrainOperation` with runtime parameters.\n\nArgs:\n    dataset_name: Name of the FiftyOne dataset to operate on.\n    brain_key: Value controlling brain key for this routine.\n\nReturns:\n    None.\n        "
            },
            {
              "name": "load_dataset",
              "signature": "(self)",
              "lineno": 28,
              "doc": "Load dataset required by this module.\n\nReturns:\n    Loaded object/data required by downstream workflow steps.\n        "
            },
            {
              "name": "run",
              "signature": "(self) -> dict[str, Any]",
              "lineno": 38,
              "doc": "Run the operation and return execution results.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n        "
            },
            {
              "name": "ensure_brain_run_exists",
              "signature": "(self, dataset, brain_key: str)",
              "lineno": 52,
              "doc": "Ensure brain run exists exists and return it.\n\nArgs:\n    dataset: FiftyOne dataset or dataset-like collection used by this operation.\n    brain_key: Value controlling brain key for this routine.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n        "
            },
            {
              "name": "_normalize_ids",
              "signature": "(values) -> list[str]",
              "lineno": 68,
              "doc": "Internal helper for normalize ids.\n\nArgs:\n    values: Value controlling values for this routine.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n        "
            },
            {
              "name": "execute",
              "signature": "(self, dataset) -> dict[str, Any]",
              "lineno": 80,
              "doc": "Perform execute.\n\nArgs:\n    dataset: FiftyOne dataset or dataset-like collection used by this operation.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n        "
            }
          ]
        }
      ],
      "functions": []
    },
    {
      "module": "src.dataset_tools.brain.duplicates",
      "file": "src/dataset_tools/brain/duplicates.py",
      "doc": "Implementation module for FiftyOne Brain analysis.",
      "classes": [
        {
          "name": "ExactDuplicatesOperation",
          "lineno": 12,
          "doc": "Operation class used in FiftyOne Brain analysis.\n    ",
          "methods": [
            {
              "name": "execute",
              "signature": "(self, dataset) -> dict[str, Any]",
              "lineno": 15,
              "doc": "Perform execute.\n\nArgs:\n    dataset: FiftyOne dataset or dataset-like collection used by this operation.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n        "
            }
          ]
        },
        {
          "name": "NearDuplicatesOperation",
          "lineno": 46,
          "doc": "Operation class used in FiftyOne Brain analysis.\n    ",
          "methods": [
            {
              "name": "__init__",
              "signature": "(self, dataset_name: str, threshold: float = 0.2, embeddings: str | None = None, roi_field: str | None = None)",
              "lineno": 49,
              "doc": "Initialize `NearDuplicatesOperation` with runtime parameters.\n\nArgs:\n    dataset_name: Name of the FiftyOne dataset to operate on.\n    threshold: Decision/filter threshold used by this operation.\n    embeddings: Value controlling embeddings for this routine.\n    roi_field: Value controlling roi field for this routine.\n\nReturns:\n    None.\n        "
            },
            {
              "name": "execute",
              "signature": "(self, dataset) -> dict[str, Any]",
              "lineno": 72,
              "doc": "Perform execute.\n\nArgs:\n    dataset: FiftyOne dataset or dataset-like collection used by this operation.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n        "
            }
          ]
        }
      ],
      "functions": []
    },
    {
      "module": "src.dataset_tools.brain.leaky_splits",
      "file": "src/dataset_tools/brain/leaky_splits.py",
      "doc": "Implementation module for FiftyOne Brain analysis.",
      "classes": [
        {
          "name": "LeakySplitsOperation",
          "lineno": 12,
          "doc": "Operation class used in FiftyOne Brain analysis.\n    ",
          "methods": [
            {
              "name": "__init__",
              "signature": "(self, dataset_name: str, splits: list[str], threshold: float = 0.2, embeddings: str | None = None, roi_field: str | None = None)",
              "lineno": 15,
              "doc": "Initialize `LeakySplitsOperation` with runtime parameters.\n\nArgs:\n    dataset_name: Name of the FiftyOne dataset to operate on.\n    splits: Value controlling splits for this routine.\n    threshold: Decision/filter threshold used by this operation.\n    embeddings: Value controlling embeddings for this routine.\n    roi_field: Value controlling roi field for this routine.\n\nReturns:\n    None.\n        "
            },
            {
              "name": "execute",
              "signature": "(self, dataset) -> dict[str, Any]",
              "lineno": 41,
              "doc": "Perform execute.\n\nArgs:\n    dataset: FiftyOne dataset or dataset-like collection used by this operation.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n        "
            }
          ]
        }
      ],
      "functions": []
    },
    {
      "module": "src.dataset_tools.brain.similarity",
      "file": "src/dataset_tools/brain/similarity.py",
      "doc": "Implementation module for FiftyOne Brain analysis.",
      "classes": [
        {
          "name": "SimilarityOperation",
          "lineno": 12,
          "doc": "Operation class used in FiftyOne Brain analysis.\n    ",
          "methods": [
            {
              "name": "__init__",
              "signature": "(self, dataset_name: str, embeddings: str | None = None, patches_field: str | None = None, roi_field: str | None = None, backend: str | None = None, brain_key: str | None = None)",
              "lineno": 15,
              "doc": "Initialize `SimilarityOperation` with runtime parameters.\n\nArgs:\n    dataset_name: Name of the FiftyOne dataset to operate on.\n    embeddings: Value controlling embeddings for this routine.\n    patches_field: Value controlling patches field for this routine.\n    roi_field: Value controlling roi field for this routine.\n    backend: Value controlling backend for this routine.\n    brain_key: Value controlling brain key for this routine.\n\nReturns:\n    None.\n        "
            },
            {
              "name": "execute",
              "signature": "(self, dataset) -> dict[str, Any]",
              "lineno": 43,
              "doc": "Perform execute.\n\nArgs:\n    dataset: FiftyOne dataset or dataset-like collection used by this operation.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n        "
            }
          ]
        }
      ],
      "functions": []
    },
    {
      "module": "src.dataset_tools.brain.visualization",
      "file": "src/dataset_tools/brain/visualization.py",
      "doc": "Implementation module for FiftyOne Brain analysis.",
      "classes": [
        {
          "name": "VisualizationOperation",
          "lineno": 12,
          "doc": "Operation class used in FiftyOne Brain analysis.\n    ",
          "methods": [
            {
              "name": "__init__",
              "signature": "(self, dataset_name: str, method: str = 'umap', num_dims: int = 2, embeddings: str | None = None, patches_field: str | None = None, brain_key: str | None = None)",
              "lineno": 15,
              "doc": "Initialize `VisualizationOperation` with runtime parameters.\n\nArgs:\n    dataset_name: Name of the FiftyOne dataset to operate on.\n    method: Value controlling method for this routine.\n    num_dims: Value controlling num dims for this routine.\n    embeddings: Value controlling embeddings for this routine.\n    patches_field: Value controlling patches field for this routine.\n    brain_key: Value controlling brain key for this routine.\n\nReturns:\n    None.\n        "
            },
            {
              "name": "execute",
              "signature": "(self, dataset) -> dict[str, Any]",
              "lineno": 43,
              "doc": "Perform execute.\n\nArgs:\n    dataset: FiftyOne dataset or dataset-like collection used by this operation.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n        "
            }
          ]
        }
      ],
      "functions": []
    },
    {
      "module": "src.dataset_tools.config",
      "file": "src/dataset_tools/config.py",
      "doc": "Central configuration schema and loader for ``dataset_tools``.\n\nThis module defines typed config dataclasses and a deterministic merge order:\n\n1. in-code defaults\n2. optional local JSON config file\n3. environment variables\n4. runtime overrides (for one-off CLI runs/jobs)",
      "classes": [
        {
          "name": "PathMountConfig",
          "lineno": 23,
          "doc": "Host/container mount mapping used for Label Studio local-files URLs.\n\n``host_root`` must be a parent of sample filepaths stored in FiftyOne.\n``ls_document_root`` is the corresponding path inside the Label Studio pod.\n``local_files_prefix`` is the URL prefix consumed by LS local-files storage.",
          "methods": []
        },
        {
          "name": "LabelStudioConfig",
          "lineno": 36,
          "doc": "Runtime settings for Label Studio connectivity and task transfer.\n\nIncludes API endpoint credentials, default project/storage metadata, and\nupload strategy controls such as batch size and backend mode.",
          "methods": []
        },
        {
          "name": "DatasetConfig",
          "lineno": 54,
          "doc": "Dataset-level defaults used by curation and sync workflows.\n\nDefines the default FiftyOne dataset name and canonical field names used\nfor source labels and pulled LS corrections.",
          "methods": []
        },
        {
          "name": "DiskSyncConfig",
          "lineno": 68,
          "doc": "Filesystem sync defaults for writing corrections back to label files.",
          "methods": []
        },
        {
          "name": "AppConfig",
          "lineno": 78,
          "doc": "Top-level immutable runtime configuration consumed by dataset_tools.",
          "methods": []
        }
      ],
      "functions": [
        {
          "name": "_default_config_dict",
          "signature": "() -> dict[str, Any]",
          "lineno": 86,
          "doc": "Return the baseline config dictionary used before any overrides."
        },
        {
          "name": "resolve_default_local_config_path",
          "signature": "() -> Path",
          "lineno": 119,
          "doc": "Resolve default local config path in a portable, install-friendly way.\n\nResolution order:\n1. ``DST_CONFIG_PATH`` environment variable\n2. package-local ``local_config.json`` when present\n3. ``$XDG_CONFIG_HOME/dst/local_config.json`` (or ``~/.config/dst/local_config.json``)"
        },
        {
          "name": "_deep_merge",
          "signature": "(base: dict[str, Any], override: dict[str, Any]) -> dict[str, Any]",
          "lineno": 139,
          "doc": "Recursively merge ``override`` into ``base`` and return a new dict.\n\nNested dictionaries are merged key-by-key; non-dict values replace existing\nvalues at the same key.\n\nArgs:\n    base: Baseline dictionary.\n    override: Override dictionary applied on top of ``base``.\n\nReturns:\n    New merged dictionary."
        },
        {
          "name": "_load_local_config",
          "signature": "(path: Path) -> dict[str, Any]",
          "lineno": 161,
          "doc": "Load optional local JSON config from ``path``.\n\nArgs:\n    path: Path to local config JSON.\n\nReturns:\n    Parsed dictionary, or an empty dict when the file does not exist."
        },
        {
          "name": "_load_env_config",
          "signature": "() -> dict[str, Any]",
          "lineno": 177,
          "doc": "Build config overrides from supported environment variables.\n\nReturns:\n    Partial config dictionary containing only keys provided in env vars."
        },
        {
          "name": "load_config",
          "signature": "(local_config_path: str | os.PathLike[str] | None = None, overrides: dict[str, Any] | None = None) -> AppConfig",
          "lineno": 216,
          "doc": "Resolve and validate the runtime ``AppConfig``.\n\nMerge precedence is:\ndefaults -> local config file -> environment variables -> ``overrides``.\n\nArgs:\n    local_config_path: Optional path to local JSON config. If omitted,\n        defaults are resolved by ``resolve_default_local_config_path()``.\n    overrides: Optional runtime override dictionary (typically from CLI).\n\nReturns:\n    Immutable ``AppConfig`` instance."
        },
        {
          "name": "require_label_studio_api_key",
          "signature": "(config: AppConfig) -> str",
          "lineno": 254,
          "doc": "Return Label Studio API key or raise a clear configuration error.\n\nArgs:\n    config: Resolved application config.\n\nReturns:\n    Non-empty Label Studio API key string.\n\nRaises:\n    RuntimeError: If the API key is missing from config/env/local file."
        }
      ]
    },
    {
      "module": "src.dataset_tools.debug",
      "file": "src/dataset_tools/debug/__init__.py",
      "doc": "Package initializer for `dataset_tools.debug`.",
      "classes": [],
      "functions": []
    },
    {
      "module": "src.dataset_tools.debug.debug_fo_import",
      "file": "src/dataset_tools/debug/debug_fo_import.py",
      "doc": "Implementation module for debug and diagnostics.",
      "classes": [],
      "functions": []
    },
    {
      "module": "src.dataset_tools.debug.debug_fob",
      "file": "src/dataset_tools/debug/debug_fob.py",
      "doc": "Implementation module for debug and diagnostics.",
      "classes": [],
      "functions": []
    },
    {
      "module": "src.dataset_tools.debug.debug_imports",
      "file": "src/dataset_tools/debug/debug_imports.py",
      "doc": "Implementation module for debug and diagnostics.",
      "classes": [],
      "functions": []
    },
    {
      "module": "src.dataset_tools.debug.debug_ls_tasks",
      "file": "src/dataset_tools/debug/debug_ls_tasks.py",
      "doc": "Implementation module for debug and diagnostics.",
      "classes": [],
      "functions": [
        {
          "name": "debug_tasks",
          "signature": "()",
          "lineno": 14,
          "doc": "Perform debug tasks.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n    "
        }
      ]
    },
    {
      "module": "src.dataset_tools.debug.debug_ls_urls",
      "file": "src/dataset_tools/debug/debug_ls_urls.py",
      "doc": "Implementation module for debug and diagnostics.",
      "classes": [],
      "functions": [
        {
          "name": "main",
          "signature": "()",
          "lineno": 16,
          "doc": "Perform main.\n\nReturns:\n    Process exit code.\n    "
        }
      ]
    },
    {
      "module": "src.dataset_tools.dst",
      "file": "src/dataset_tools/dst.py",
      "doc": "Dataset Tools unified CLI entrypoint (`dst`).\n\nThis module defines argument parsing, command dispatch, and thin orchestration handlers that call\ninto the `dataset_tools` packages (loaders, metrics, brain, workflows, Label Studio sync, anomaly, and models).\nEach `cmd_*` function returns structured payloads so execution can be inspected, tested, and optionally\nwritten to JSON by automation jobs.",
      "classes": [],
      "functions": [
        {
          "name": "_parse_json_value",
          "signature": "(raw: str, label: str) -> Any",
          "lineno": 22,
          "doc": "Parse raw JSON text for a named CLI argument and raise readable errors.\n    "
        },
        {
          "name": "_parse_json_dict",
          "signature": "(raw: str | None, label: str) -> dict[str, Any]",
          "lineno": 31,
          "doc": "Parse an optional JSON object argument and normalize missing values to empty dicts.\n    "
        },
        {
          "name": "_parse_json_list",
          "signature": "(raw: str, label: str) -> list[Any]",
          "lineno": 44,
          "doc": "Parse and validate a JSON array argument from the CLI.\n    "
        },
        {
          "name": "_parse_csv_list",
          "signature": "(raw: str, label: str) -> list[str]",
          "lineno": 53,
          "doc": "Parse a comma-separated CLI value into a non-empty list of tokens.\n    "
        },
        {
          "name": "_parse_class_map",
          "signature": "(raw: str | None) -> dict[int, str]",
          "lineno": 63,
          "doc": "Convert class-map JSON into an integer-keyed mapping for YOLO loaders.\n    "
        },
        {
          "name": "_parse_path_replacements",
          "signature": "(entries: Iterable[str] | None) -> tuple[tuple[str, str], ...] | None",
          "lineno": 77,
          "doc": "Parse repeated SRC=DST replacement rules used by disk sync routines.\n    "
        },
        {
          "name": "_parse_optional_text",
          "signature": "(raw: str | None) -> str | None",
          "lineno": 97,
          "doc": "Normalize empty/None-like strings into Python None for optional fields.\n    "
        },
        {
          "name": "_parse_devices",
          "signature": "(raw: str | int | None) -> str | int | None",
          "lineno": 110,
          "doc": "Normalize anomaly `--devices` input to an int, string selector, or None.\n    "
        },
        {
          "name": "_load_app_config",
          "signature": "(args) -> Any",
          "lineno": 125,
          "doc": "Load the resolved application configuration from defaults, local config, and overrides.\n    "
        },
        {
          "name": "_list_projects",
          "signature": "(ls) -> list[Any]",
          "lineno": 135,
          "doc": "List Label Studio projects while supporting API version differences.\n    "
        },
        {
          "name": "_project_payload",
          "signature": "(project, include_task_count: bool = False) -> dict[str, Any]",
          "lineno": 145,
          "doc": "Convert a Label Studio project object into a stable dictionary payload.\n    "
        },
        {
          "name": "_mask_api_key",
          "signature": "(value: str) -> str",
          "lineno": 162,
          "doc": "Mask secret tokens before printing config payloads.\n    "
        },
        {
          "name": "_print_result",
          "signature": "(result: Any)",
          "lineno": 172,
          "doc": "Render command output payloads to stdout in a consistent format.\n    "
        },
        {
          "name": "_write_json_output",
          "signature": "(path: str | None, payload: Any)",
          "lineno": 185,
          "doc": "Optionally persist command results to a JSON file path.\n    "
        },
        {
          "name": "_execute_with_optional_log_capture",
          "signature": "(fn, quiet_logs: bool)",
          "lineno": 197,
          "doc": "Execute a callable while optionally suppressing noisy library logs.\n\nWhen `quiet_logs=True`, stdout/stderr and selected library loggers are captured to keep CLI output clean. If execution fails, captured logs are replayed to stderr for debugging context before the exception is re-raised.\n    "
        },
        {
          "name": "cmd_config_show",
          "signature": "(args)",
          "lineno": 242,
          "doc": "Run the `dst config show` command handler and return a JSON-serializable result.\n\nThis handler is invoked by argparse for the `config show` command path. It performs argument normalization, calls into the corresponding dataset_tools module, and returns a payload that can be printed or persisted with `--output-json`.\n\nExpected setup:\n    - Python environment has FiftyOne and optional provider dependencies installed.\n    - External services (for LS commands) are reachable and credentials are configured.\n    - Dataset names/fields referenced by CLI arguments exist when required.\n\nRaises:\n    ValueError: If argument combinations are invalid for the selected backend.\n    RuntimeError: If required datasets/projects/services cannot be resolved.\n    "
        },
        {
          "name": "cmd_ls_test",
          "signature": "(args)",
          "lineno": 265,
          "doc": "Run the `dst ls test` command handler and return a JSON-serializable result.\n\nThis handler is invoked by argparse for the `ls test` command path. It performs argument normalization, calls into the corresponding dataset_tools module, and returns a payload that can be printed or persisted with `--output-json`.\n\nExpected setup:\n    - Python environment has FiftyOne and optional provider dependencies installed.\n    - External services (for LS commands) are reachable and credentials are configured.\n    - Dataset names/fields referenced by CLI arguments exist when required.\n\nRaises:\n    ValueError: If argument combinations are invalid for the selected backend.\n    RuntimeError: If required datasets/projects/services cannot be resolved.\n    "
        },
        {
          "name": "cmd_ls_project_list",
          "signature": "(args)",
          "lineno": 297,
          "doc": "Run the `dst ls project list` command handler and return a JSON-serializable result.\n\nThis handler is invoked by argparse for the `ls project list` command path. It performs argument normalization, calls into the corresponding dataset_tools module, and returns a payload that can be printed or persisted with `--output-json`.\n\nExpected setup:\n    - Python environment has FiftyOne and optional provider dependencies installed.\n    - External services (for LS commands) are reachable and credentials are configured.\n    - Dataset names/fields referenced by CLI arguments exist when required.\n\nRaises:\n    ValueError: If argument combinations are invalid for the selected backend.\n    RuntimeError: If required datasets/projects/services cannot be resolved.\n    "
        },
        {
          "name": "_resolve_project",
          "signature": "(ls, project_id: int | None, project_title: str | None)",
          "lineno": 337,
          "doc": "Resolve a Label Studio project by id or exact title.\n    "
        },
        {
          "name": "cmd_ls_project_clear_tasks",
          "signature": "(args)",
          "lineno": 358,
          "doc": "Run the `dst ls project clear tasks` command handler and return a JSON-serializable result.\n\nThis handler is invoked by argparse for the `ls project clear tasks` command path. It performs argument normalization, calls into the corresponding dataset_tools module, and returns a payload that can be printed or persisted with `--output-json`.\n\nExpected setup:\n    - Python environment has FiftyOne and optional provider dependencies installed.\n    - External services (for LS commands) are reachable and credentials are configured.\n    - Dataset names/fields referenced by CLI arguments exist when required.\n\nRaises:\n    ValueError: If argument combinations are invalid for the selected backend.\n    RuntimeError: If required datasets/projects/services cannot be resolved.\n    "
        },
        {
          "name": "cmd_ls_project_cleanup",
          "signature": "(args)",
          "lineno": 392,
          "doc": "Run the `dst ls project cleanup` command handler and return a JSON-serializable result.\n\nThis handler is invoked by argparse for the `ls project cleanup` command path. It performs argument normalization, calls into the corresponding dataset_tools module, and returns a payload that can be printed or persisted with `--output-json`.\n\nExpected setup:\n    - Python environment has FiftyOne and optional provider dependencies installed.\n    - External services (for LS commands) are reachable and credentials are configured.\n    - Dataset names/fields referenced by CLI arguments exist when required.\n\nRaises:\n    ValueError: If argument combinations are invalid for the selected backend.\n    RuntimeError: If required datasets/projects/services cannot be resolved.\n    "
        },
        {
          "name": "cmd_data_load_yolo",
          "signature": "(args)",
          "lineno": 439,
          "doc": "Run the `dst data load yolo` command handler and return a JSON-serializable result.\n\nThis handler is invoked by argparse for the `data load yolo` command path. It performs argument normalization, calls into the corresponding dataset_tools module, and returns a payload that can be printed or persisted with `--output-json`.\n\nExpected setup:\n    - Python environment has FiftyOne and optional provider dependencies installed.\n    - External services (for LS commands) are reachable and credentials are configured.\n    - Dataset names/fields referenced by CLI arguments exist when required.\n\nRaises:\n    ValueError: If argument combinations are invalid for the selected backend.\n    RuntimeError: If required datasets/projects/services cannot be resolved.\n    "
        },
        {
          "name": "cmd_data_load_coco",
          "signature": "(args)",
          "lineno": 499,
          "doc": "Run the `dst data load coco` command handler and return a JSON-serializable result.\n\nThis handler is invoked by argparse for the `data load coco` command path. It performs argument normalization, calls into the corresponding dataset_tools module, and returns a payload that can be printed or persisted with `--output-json`.\n\nExpected setup:\n    - Python environment has FiftyOne and optional provider dependencies installed.\n    - External services (for LS commands) are reachable and credentials are configured.\n    - Dataset names/fields referenced by CLI arguments exist when required.\n\nRaises:\n    ValueError: If argument combinations are invalid for the selected backend.\n    RuntimeError: If required datasets/projects/services cannot be resolved.\n    "
        },
        {
          "name": "cmd_data_export_ls_json",
          "signature": "(args)",
          "lineno": 538,
          "doc": "Run the `dst data export ls json` command handler and return a JSON-serializable result.\n\nThis handler is invoked by argparse for the `data export ls json` command path. It performs argument normalization, calls into the corresponding dataset_tools module, and returns a payload that can be printed or persisted with `--output-json`.\n\nExpected setup:\n    - Python environment has FiftyOne and optional provider dependencies installed.\n    - External services (for LS commands) are reachable and credentials are configured.\n    - Dataset names/fields referenced by CLI arguments exist when required.\n\nRaises:\n    ValueError: If argument combinations are invalid for the selected backend.\n    RuntimeError: If required datasets/projects/services cannot be resolved.\n    "
        },
        {
          "name": "cmd_metrics_embeddings",
          "signature": "(args)",
          "lineno": 567,
          "doc": "Run the `dst metrics embeddings` command handler and return a JSON-serializable result.\n\nThis handler is invoked by argparse for the `metrics embeddings` command path. It performs argument normalization, calls into the corresponding dataset_tools module, and returns a payload that can be printed or persisted with `--output-json`.\n\nExpected setup:\n    - Python environment has FiftyOne and optional provider dependencies installed.\n    - External services (for LS commands) are reachable and credentials are configured.\n    - Dataset names/fields referenced by CLI arguments exist when required.\n\nRaises:\n    ValueError: If argument combinations are invalid for the selected backend.\n    RuntimeError: If required datasets/projects/services cannot be resolved.\n    "
        },
        {
          "name": "cmd_metrics_uniqueness",
          "signature": "(args)",
          "lineno": 596,
          "doc": "Run the `dst metrics uniqueness` command handler and return a JSON-serializable result.\n\nThis handler is invoked by argparse for the `metrics uniqueness` command path. It performs argument normalization, calls into the corresponding dataset_tools module, and returns a payload that can be printed or persisted with `--output-json`.\n\nExpected setup:\n    - Python environment has FiftyOne and optional provider dependencies installed.\n    - External services (for LS commands) are reachable and credentials are configured.\n    - Dataset names/fields referenced by CLI arguments exist when required.\n\nRaises:\n    ValueError: If argument combinations are invalid for the selected backend.\n    RuntimeError: If required datasets/projects/services cannot be resolved.\n    "
        },
        {
          "name": "cmd_metrics_mistakenness",
          "signature": "(args)",
          "lineno": 620,
          "doc": "Run the `dst metrics mistakenness` command handler and return a JSON-serializable result.\n\nThis handler is invoked by argparse for the `metrics mistakenness` command path. It performs argument normalization, calls into the corresponding dataset_tools module, and returns a payload that can be printed or persisted with `--output-json`.\n\nExpected setup:\n    - Python environment has FiftyOne and optional provider dependencies installed.\n    - External services (for LS commands) are reachable and credentials are configured.\n    - Dataset names/fields referenced by CLI arguments exist when required.\n\nRaises:\n    ValueError: If argument combinations are invalid for the selected backend.\n    RuntimeError: If required datasets/projects/services cannot be resolved.\n    "
        },
        {
          "name": "cmd_metrics_hardness",
          "signature": "(args)",
          "lineno": 647,
          "doc": "Run the `dst metrics hardness` command handler and return a JSON-serializable result.\n\nThis handler is invoked by argparse for the `metrics hardness` command path. It performs argument normalization, calls into the corresponding dataset_tools module, and returns a payload that can be printed or persisted with `--output-json`.\n\nExpected setup:\n    - Python environment has FiftyOne and optional provider dependencies installed.\n    - External services (for LS commands) are reachable and credentials are configured.\n    - Dataset names/fields referenced by CLI arguments exist when required.\n\nRaises:\n    ValueError: If argument combinations are invalid for the selected backend.\n    RuntimeError: If required datasets/projects/services cannot be resolved.\n    "
        },
        {
          "name": "cmd_metrics_representativeness",
          "signature": "(args)",
          "lineno": 671,
          "doc": "Run the `dst metrics representativeness` command handler and return a JSON-serializable result.\n\nThis handler is invoked by argparse for the `metrics representativeness` command path. It performs argument normalization, calls into the corresponding dataset_tools module, and returns a payload that can be printed or persisted with `--output-json`.\n\nExpected setup:\n    - Python environment has FiftyOne and optional provider dependencies installed.\n    - External services (for LS commands) are reachable and credentials are configured.\n    - Dataset names/fields referenced by CLI arguments exist when required.\n\nRaises:\n    ValueError: If argument combinations are invalid for the selected backend.\n    RuntimeError: If required datasets/projects/services cannot be resolved.\n    "
        },
        {
          "name": "cmd_brain_visualization",
          "signature": "(args)",
          "lineno": 697,
          "doc": "Run the `dst brain visualization` command handler and return a JSON-serializable result.\n\nThis handler is invoked by argparse for the `brain visualization` command path. It performs argument normalization, calls into the corresponding dataset_tools module, and returns a payload that can be printed or persisted with `--output-json`.\n\nExpected setup:\n    - Python environment has FiftyOne and optional provider dependencies installed.\n    - External services (for LS commands) are reachable and credentials are configured.\n    - Dataset names/fields referenced by CLI arguments exist when required.\n\nRaises:\n    ValueError: If argument combinations are invalid for the selected backend.\n    RuntimeError: If required datasets/projects/services cannot be resolved.\n    "
        },
        {
          "name": "cmd_brain_similarity",
          "signature": "(args)",
          "lineno": 724,
          "doc": "Run the `dst brain similarity` command handler and return a JSON-serializable result.\n\nThis handler is invoked by argparse for the `brain similarity` command path. It performs argument normalization, calls into the corresponding dataset_tools module, and returns a payload that can be printed or persisted with `--output-json`.\n\nExpected setup:\n    - Python environment has FiftyOne and optional provider dependencies installed.\n    - External services (for LS commands) are reachable and credentials are configured.\n    - Dataset names/fields referenced by CLI arguments exist when required.\n\nRaises:\n    ValueError: If argument combinations are invalid for the selected backend.\n    RuntimeError: If required datasets/projects/services cannot be resolved.\n    "
        },
        {
          "name": "cmd_brain_duplicates_exact",
          "signature": "(args)",
          "lineno": 751,
          "doc": "Run the `dst brain duplicates exact` command handler and return a JSON-serializable result.\n\nThis handler is invoked by argparse for the `brain duplicates exact` command path. It performs argument normalization, calls into the corresponding dataset_tools module, and returns a payload that can be printed or persisted with `--output-json`.\n\nExpected setup:\n    - Python environment has FiftyOne and optional provider dependencies installed.\n    - External services (for LS commands) are reachable and credentials are configured.\n    - Dataset names/fields referenced by CLI arguments exist when required.\n\nRaises:\n    ValueError: If argument combinations are invalid for the selected backend.\n    RuntimeError: If required datasets/projects/services cannot be resolved.\n    "
        },
        {
          "name": "cmd_brain_duplicates_near",
          "signature": "(args)",
          "lineno": 771,
          "doc": "Run the `dst brain duplicates near` command handler and return a JSON-serializable result.\n\nThis handler is invoked by argparse for the `brain duplicates near` command path. It performs argument normalization, calls into the corresponding dataset_tools module, and returns a payload that can be printed or persisted with `--output-json`.\n\nExpected setup:\n    - Python environment has FiftyOne and optional provider dependencies installed.\n    - External services (for LS commands) are reachable and credentials are configured.\n    - Dataset names/fields referenced by CLI arguments exist when required.\n\nRaises:\n    ValueError: If argument combinations are invalid for the selected backend.\n    RuntimeError: If required datasets/projects/services cannot be resolved.\n    "
        },
        {
          "name": "cmd_brain_leaky_splits",
          "signature": "(args)",
          "lineno": 796,
          "doc": "Run the `dst brain leaky splits` command handler and return a JSON-serializable result.\n\nThis handler is invoked by argparse for the `brain leaky splits` command path. It performs argument normalization, calls into the corresponding dataset_tools module, and returns a payload that can be printed or persisted with `--output-json`.\n\nExpected setup:\n    - Python environment has FiftyOne and optional provider dependencies installed.\n    - External services (for LS commands) are reachable and credentials are configured.\n    - Dataset names/fields referenced by CLI arguments exist when required.\n\nRaises:\n    ValueError: If argument combinations are invalid for the selected backend.\n    RuntimeError: If required datasets/projects/services cannot be resolved.\n    "
        },
        {
          "name": "cmd_models_list",
          "signature": "(args)",
          "lineno": 824,
          "doc": "Run the `dst models list` command handler and return a JSON-serializable result.\n\nThis handler is invoked by argparse for the `models list` command path. It performs argument normalization, calls into the corresponding dataset_tools module, and returns a payload that can be printed or persisted with `--output-json`.\n\nExpected setup:\n    - Python environment has FiftyOne and optional provider dependencies installed.\n    - External services (for LS commands) are reachable and credentials are configured.\n    - Dataset names/fields referenced by CLI arguments exist when required.\n\nRaises:\n    ValueError: If argument combinations are invalid for the selected backend.\n    RuntimeError: If required datasets/projects/services cannot be resolved.\n    "
        },
        {
          "name": "cmd_models_resolve",
          "signature": "(args)",
          "lineno": 858,
          "doc": "Run the `dst models resolve` command handler and return a JSON-serializable result.\n\nThis handler is invoked by argparse for the `models resolve` command path. It performs argument normalization, calls into the corresponding dataset_tools module, and returns a payload that can be printed or persisted with `--output-json`.\n\nExpected setup:\n    - Python environment has FiftyOne and optional provider dependencies installed.\n    - External services (for LS commands) are reachable and credentials are configured.\n    - Dataset names/fields referenced by CLI arguments exist when required.\n\nRaises:\n    ValueError: If argument combinations are invalid for the selected backend.\n    RuntimeError: If required datasets/projects/services cannot be resolved.\n    "
        },
        {
          "name": "cmd_models_validate",
          "signature": "(args)",
          "lineno": 890,
          "doc": "Run the `dst models validate` command handler and return a JSON-serializable result.\n\nThis handler is invoked by argparse for the `models validate` command path. It performs argument normalization, calls into the corresponding dataset_tools module, and returns a payload that can be printed or persisted with `--output-json`.\n\nExpected setup:\n    - Python environment has FiftyOne and optional provider dependencies installed.\n    - External services (for LS commands) are reachable and credentials are configured.\n    - Dataset names/fields referenced by CLI arguments exist when required.\n\nRaises:\n    ValueError: If argument combinations are invalid for the selected backend.\n    RuntimeError: If required datasets/projects/services cannot be resolved.\n    "
        },
        {
          "name": "cmd_anomaly_fit",
          "signature": "(args)",
          "lineno": 909,
          "doc": "Run the `dst anomaly fit` command handler and return a JSON-serializable result.\n\nThis handler is invoked by argparse for the `anomaly fit` command path. It performs argument normalization, calls into the corresponding dataset_tools module, and returns a payload that can be printed or persisted with `--output-json`.\n\nExpected setup:\n    - Python environment has FiftyOne and optional provider dependencies installed.\n    - External services (for LS commands) are reachable and credentials are configured.\n    - Dataset names/fields referenced by CLI arguments exist when required.\n\nRaises:\n    ValueError: If argument combinations are invalid for the selected backend.\n    RuntimeError: If required datasets/projects/services cannot be resolved.\n    "
        },
        {
          "name": "cmd_anomaly_train",
          "signature": "(args)",
          "lineno": 947,
          "doc": "Run the `dst anomaly train` command handler and return a JSON-serializable result.\n\nThis handler is invoked by argparse for the `anomaly train` command path. It performs argument normalization, calls into the corresponding dataset_tools module, and returns a payload that can be printed or persisted with `--output-json`.\n\nExpected setup:\n    - Python environment has FiftyOne and optional provider dependencies installed.\n    - External services (for LS commands) are reachable and credentials are configured.\n    - Dataset names/fields referenced by CLI arguments exist when required.\n\nRaises:\n    ValueError: If argument combinations are invalid for the selected backend.\n    RuntimeError: If required datasets/projects/services cannot be resolved.\n    "
        },
        {
          "name": "cmd_anomaly_score",
          "signature": "(args)",
          "lineno": 1004,
          "doc": "Run the `dst anomaly score` command handler and return a JSON-serializable result.\n\nThis handler is invoked by argparse for the `anomaly score` command path. It performs argument normalization, calls into the corresponding dataset_tools module, and returns a payload that can be printed or persisted with `--output-json`.\n\nExpected setup:\n    - Python environment has FiftyOne and optional provider dependencies installed.\n    - External services (for LS commands) are reachable and credentials are configured.\n    - Dataset names/fields referenced by CLI arguments exist when required.\n\nRaises:\n    ValueError: If argument combinations are invalid for the selected backend.\n    RuntimeError: If required datasets/projects/services cannot be resolved.\n    "
        },
        {
          "name": "cmd_anomaly_run",
          "signature": "(args)",
          "lineno": 1073,
          "doc": "Run the `dst anomaly run` command handler and return a JSON-serializable result.\n\nThis handler is invoked by argparse for the `anomaly run` command path. It performs argument normalization, calls into the corresponding dataset_tools module, and returns a payload that can be printed or persisted with `--output-json`.\n\nExpected setup:\n    - Python environment has FiftyOne and optional provider dependencies installed.\n    - External services (for LS commands) are reachable and credentials are configured.\n    - Dataset names/fields referenced by CLI arguments exist when required.\n\nRaises:\n    ValueError: If argument combinations are invalid for the selected backend.\n    RuntimeError: If required datasets/projects/services cannot be resolved.\n    "
        },
        {
          "name": "cmd_workflow_roundtrip",
          "signature": "(args)",
          "lineno": 1126,
          "doc": "Run the `dst workflow roundtrip` command handler and return a JSON-serializable result.\n\nThis handler is invoked by argparse for the `workflow roundtrip` command path. It performs argument normalization, calls into the corresponding dataset_tools module, and returns a payload that can be printed or persisted with `--output-json`.\n\nExpected setup:\n    - Python environment has FiftyOne and optional provider dependencies installed.\n    - External services (for LS commands) are reachable and credentials are configured.\n    - Dataset names/fields referenced by CLI arguments exist when required.\n\nRaises:\n    ValueError: If argument combinations are invalid for the selected backend.\n    RuntimeError: If required datasets/projects/services cannot be resolved.\n    "
        },
        {
          "name": "_build_tag_rules",
          "signature": "(payload_rules: list[dict[str, Any]])",
          "lineno": 1192,
          "doc": "Translate JSON workflow rules into typed tag-workflow rule objects.\n    "
        },
        {
          "name": "cmd_workflow_tags_run",
          "signature": "(args)",
          "lineno": 1207,
          "doc": "Run the `dst workflow tags run` command handler and return a JSON-serializable result.\n\nThis handler is invoked by argparse for the `workflow tags run` command path. It performs argument normalization, calls into the corresponding dataset_tools module, and returns a payload that can be printed or persisted with `--output-json`.\n\nExpected setup:\n    - Python environment has FiftyOne and optional provider dependencies installed.\n    - External services (for LS commands) are reachable and credentials are configured.\n    - Dataset names/fields referenced by CLI arguments exist when required.\n\nRaises:\n    ValueError: If argument combinations are invalid for the selected backend.\n    RuntimeError: If required datasets/projects/services cannot be resolved.\n    "
        },
        {
          "name": "cmd_workflow_tags_inline",
          "signature": "(args)",
          "lineno": 1266,
          "doc": "Run the `dst workflow tags inline` command handler and return a JSON-serializable result.\n\nThis handler is invoked by argparse for the `workflow tags inline` command path. It performs argument normalization, calls into the corresponding dataset_tools module, and returns a payload that can be printed or persisted with `--output-json`.\n\nExpected setup:\n    - Python environment has FiftyOne and optional provider dependencies installed.\n    - External services (for LS commands) are reachable and credentials are configured.\n    - Dataset names/fields referenced by CLI arguments exist when required.\n\nRaises:\n    ValueError: If argument combinations are invalid for the selected backend.\n    RuntimeError: If required datasets/projects/services cannot be resolved.\n    "
        },
        {
          "name": "cmd_sync_disk",
          "signature": "(args)",
          "lineno": 1302,
          "doc": "Run the `dst sync disk` command handler and return a JSON-serializable result.\n\nThis handler is invoked by argparse for the `sync disk` command path. It performs argument normalization, calls into the corresponding dataset_tools module, and returns a payload that can be printed or persisted with `--output-json`.\n\nExpected setup:\n    - Python environment has FiftyOne and optional provider dependencies installed.\n    - External services (for LS commands) are reachable and credentials are configured.\n    - Dataset names/fields referenced by CLI arguments exist when required.\n\nRaises:\n    ValueError: If argument combinations are invalid for the selected backend.\n    RuntimeError: If required datasets/projects/services cannot be resolved.\n    "
        },
        {
          "name": "cmd_app_open",
          "signature": "(args)",
          "lineno": 1342,
          "doc": "Run the `dst app open` command handler and return a JSON-serializable result.\n\nThis handler is invoked by argparse for the `app open` command path. It performs argument normalization, calls into the corresponding dataset_tools module, and returns a payload that can be printed or persisted with `--output-json`.\n\nExpected setup:\n    - Python environment has FiftyOne and optional provider dependencies installed.\n    - External services (for LS commands) are reachable and credentials are configured.\n    - Dataset names/fields referenced by CLI arguments exist when required.\n\nRaises:\n    ValueError: If argument combinations are invalid for the selected backend.\n    RuntimeError: If required datasets/projects/services cannot be resolved.\n    "
        },
        {
          "name": "_add_common_config_args",
          "signature": "(parser: argparse.ArgumentParser)",
          "lineno": 1384,
          "doc": "Attach shared `--config` and `--overrides` arguments to a parser.\n    "
        },
        {
          "name": "_add_persistent_args",
          "signature": "(parser: argparse.ArgumentParser)",
          "lineno": 1399,
          "doc": "Attach mutually-exclusive persistence flags to loader commands.\n    "
        },
        {
          "name": "build_parser",
          "signature": "() -> argparse.ArgumentParser",
          "lineno": 1407,
          "doc": "Build and return the full `dst` argparse command tree.\n\nThe parser intentionally maps each subcommand to a dedicated `cmd_*` handler via `set_defaults(func=...)` so behavior is explicit and testable. Use this function as the canonical source of CLI contract.\n    "
        },
        {
          "name": "main",
          "signature": "(argv: list[str] | None = None) -> int",
          "lineno": 1857,
          "doc": "CLI program entrypoint used by `./dst` and `python -m dataset_tools.dst`.\n\nThis function parses argv, dispatches to the resolved command handler, converts known runtime/config errors into argparse-style user-facing errors, and prints the resulting payload.\n    "
        }
      ]
    },
    {
      "module": "src.dataset_tools.label_studio",
      "file": "src/dataset_tools/label_studio/__init__.py",
      "doc": "Package initializer for `dataset_tools.label_studio`.",
      "classes": [],
      "functions": []
    },
    {
      "module": "src.dataset_tools.label_studio.client",
      "file": "src/dataset_tools/label_studio/client.py",
      "doc": "Implementation module for Label Studio integration.",
      "classes": [],
      "functions": [
        {
          "name": "_import_label_studio_client",
          "signature": "() -> Any",
          "lineno": 15,
          "doc": "Internal helper for import label studio client.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n    "
        },
        {
          "name": "_resolve_access_token",
          "signature": "(url: str, api_key: str) -> str",
          "lineno": 36,
          "doc": "Resolve access token from provided inputs.\n\nArgs:\n    url: Value controlling url for this routine.\n    api_key: Value controlling api key for this routine.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n    "
        },
        {
          "name": "connect_to_label_studio",
          "signature": "(url: str, api_key: str)",
          "lineno": 67,
          "doc": "Connect to to label studio and return a ready client.\n\nArgs:\n    url: Value controlling url for this routine.\n    api_key: Value controlling api key for this routine.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n    "
        },
        {
          "name": "ensure_label_studio_client",
          "signature": "(config: AppConfig)",
          "lineno": 88,
          "doc": "Ensure label studio client exists and return it.\n\nArgs:\n    config: Configuration object controlling runtime behavior.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n    "
        }
      ]
    },
    {
      "module": "src.dataset_tools.label_studio.storage",
      "file": "src/dataset_tools/label_studio/storage.py",
      "doc": "Implementation module for Label Studio integration.",
      "classes": [],
      "functions": [
        {
          "name": "_is_local_storage",
          "signature": "(storage: dict) -> bool",
          "lineno": 11,
          "doc": "Internal helper for is local storage.\n\nArgs:\n    storage: Value controlling storage for this routine.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n    "
        },
        {
          "name": "build_rectangle_label_config",
          "signature": "(labels: Iterable[str]) -> str",
          "lineno": 23,
          "doc": "Build rectangle label config for downstream steps.\n\nArgs:\n    labels: Value controlling labels for this routine.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n    "
        },
        {
          "name": "_list_projects",
          "signature": "(ls)",
          "lineno": 53,
          "doc": "List available projects.\n\nArgs:\n    ls: Connected Label Studio client instance.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n    "
        },
        {
          "name": "find_project",
          "signature": "(ls, title: str)",
          "lineno": 69,
          "doc": "Perform find project.\n\nArgs:\n    ls: Connected Label Studio client instance.\n    title: Value controlling title for this routine.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n    "
        },
        {
          "name": "ensure_project",
          "signature": "(ls, config: AppConfig, title: str | None = None, label_config: str | None = None)",
          "lineno": 85,
          "doc": "Ensure project exists and return it.\n\nArgs:\n    ls: Connected Label Studio client instance.\n    config: Configuration object controlling runtime behavior.\n    title: Value controlling title for this routine.\n    label_config: Value controlling label config for this routine.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n    "
        },
        {
          "name": "ensure_local_storage",
          "signature": "(ls, project, config: AppConfig)",
          "lineno": 117,
          "doc": "Ensure local storage exists and return it.\n\nArgs:\n    ls: Connected Label Studio client instance.\n    project: Label Studio project object.\n    config: Configuration object controlling runtime behavior.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n    "
        },
        {
          "name": "ensure_target_storage",
          "signature": "(ls, project, config: AppConfig)",
          "lineno": 154,
          "doc": "Ensure target storage exists and return it.\n\nArgs:\n    ls: Connected Label Studio client instance.\n    project: Label Studio project object.\n    config: Configuration object controlling runtime behavior.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n    "
        }
      ]
    },
    {
      "module": "src.dataset_tools.label_studio.sync",
      "file": "src/dataset_tools/label_studio/sync.py",
      "doc": "Push/pull synchronization helpers between FiftyOne and Label Studio.\n\nThis module contains the low-level transfer and reconciliation logic used by\nworkflow operations:\n\n- push samples from a FiftyOne view into Label Studio tasks\n- validate mount/storage preconditions before upload\n- pull submitted annotations back into FiftyOne fields",
      "classes": [],
      "functions": [
        {
          "name": "_set_label_studio_env",
          "signature": "(url: str, api_key: str)",
          "lineno": 24,
          "doc": "Export LS credentials into env vars used by FiftyOne annotate backend."
        },
        {
          "name": "push_view_to_label_studio",
          "signature": "(view, config: AppConfig, project_name: str | None = None, annotation_key: str | None = None, label_field: str | None = None, launch_editor: bool = False, overwrite_annotation_run: bool = True)",
          "lineno": 32,
          "doc": "Push a view to Label Studio using FiftyOne's annotate backend.\n\nThis path preserves annotation-run metadata (``uploaded_tasks``), which can\nlater be used for annotation-run based pulling.\n\nArgs:\n    view: FiftyOne view whose samples should be exported.\n    config: Resolved application configuration.\n    project_name: Optional Label Studio project title.\n    annotation_key: Optional annotation run key; defaults to project/timestamp.\n    label_field: Optional source detections field. Defaults from config.\n    launch_editor: If true, launch editor immediately after task creation.\n    overwrite_annotation_run: If true, delete existing annotation run with\n        the same key before creating a new one.\n\nReturns:\n    FiftyOne annotation results object returned by ``view.annotate(...)``."
        },
        {
          "name": "_to_local_files_url",
          "signature": "(filepath: str, config: AppConfig) -> str | None",
          "lineno": 83,
          "doc": "Convert an absolute filepath into Label Studio local-files URL.\n\nReturns ``None`` when the filepath is outside ``mount.host_root``."
        },
        {
          "name": "preflight_validate_upload",
          "signature": "(view, project, config: AppConfig, strategy: str, strict: bool = True, ls_client = None) -> dict[str, Any]",
          "lineno": 104,
          "doc": "Validate upload prerequisites before sending tasks to Label Studio.\n\nChecks:\n- required import/export local storages are attached to project\n- sample filepaths exist on disk\n- filepaths can be mapped to LS local-files URLs for SDK upload path\n\nArgs:\n    view: FiftyOne view planned for upload.\n    project: Target Label Studio project.\n    config: Resolved application configuration.\n    strategy: Upload strategy (``annotate_batched`` or ``sdk_batched``).\n    strict: When true with ``sdk_batched``, reject partial mappability.\n    ls_client: Optional client used to re-fetch project after storage changes.\n\nReturns:\n    Diagnostics payload summarizing preflight checks.\n\nRaises:\n    RuntimeError: If any required storage/filesystem/mapping check fails."
        },
        {
          "name": "push_view_to_label_studio_sdk",
          "signature": "(view, project, config: AppConfig, label_field: str | None = None) -> int",
          "lineno": 212,
          "doc": "Push a view to Label Studio via direct SDK batched task import.\n\nThis path writes ``meta.fiftyone_id`` into each task for robust SDK-based\npull mapping, and chunks uploads by configured batch size.\n\nArgs:\n    view: FiftyOne view to export.\n    project: Target Label Studio project.\n    config: Resolved application configuration.\n    label_field: Optional source detections field for predictions payload.\n\nReturns:\n    Number of tasks imported into the project."
        },
        {
          "name": "delete_project_tasks",
          "signature": "(project)",
          "lineno": 266,
          "doc": "Delete all tasks from a Label Studio project."
        },
        {
          "name": "pull_labeled_tasks_to_fiftyone",
          "signature": "(dataset, project, corrections_field: str = 'ls_corrections') -> int",
          "lineno": 271,
          "doc": "Pull submitted LS tasks into FiftyOne using task metadata mapping.\n\nMapping priority:\n- ``task.meta.fiftyone_id``\n- ``task.data.meta.fiftyone_id`` (legacy shape)\n\nOnly rectangle labels are converted and stored in ``corrections_field``.\n\nArgs:\n    dataset: Target FiftyOne dataset.\n    project: Label Studio project containing labeled tasks.\n    corrections_field: Destination field for pulled detections.\n\nReturns:\n    Number of samples updated in FiftyOne."
        },
        {
          "name": "pull_labeled_tasks_from_annotation_run",
          "signature": "(dataset, ls_client, annotation_key: str, corrections_field: str = 'ls_corrections') -> int",
          "lineno": 328,
          "doc": "Pull LS annotations by replaying a FiftyOne annotation-run task map.\n\nThis path is intended for annotate-based upload runs where task IDs are\ntracked in ``uploaded_tasks`` within annotation results.\n\nArgs:\n    dataset: Target FiftyOne dataset.\n    ls_client: Connected Label Studio client.\n    annotation_key: Annotation run key used during send.\n    corrections_field: Destination field for pulled detections.\n\nReturns:\n    Number of samples updated in FiftyOne.\n\nRaises:\n    RuntimeError: If annotation run metadata cannot be loaded."
        }
      ]
    },
    {
      "module": "src.dataset_tools.label_studio.translator",
      "file": "src/dataset_tools/label_studio/translator.py",
      "doc": "Implementation module for Label Studio integration.",
      "classes": [],
      "functions": [
        {
          "name": "_safe_percent",
          "signature": "(value: float) -> float",
          "lineno": 8,
          "doc": "Internal helper for safe percent.\n\nArgs:\n    value: Input value to normalize or validate.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n    "
        },
        {
          "name": "fo_detection_to_ls_result",
          "signature": "(det: Any, default_label: str = 'Insect') -> dict[str, Any]",
          "lineno": 20,
          "doc": "Perform fo detection to ls result.\n\nArgs:\n    det: Value controlling det for this routine.\n    default_label: Value controlling default label for this routine.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n    "
        },
        {
          "name": "ls_rectangle_result_to_fo_detection",
          "signature": "(result: dict[str, Any])",
          "lineno": 54,
          "doc": "Perform ls rectangle result to fo detection.\n\nArgs:\n    result: Value controlling result for this routine.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n    "
        }
      ]
    },
    {
      "module": "src.dataset_tools.label_studio.uploader",
      "file": "src/dataset_tools/label_studio/uploader.py",
      "doc": "Implementation module for Label Studio integration.",
      "classes": [],
      "functions": [
        {
          "name": "install_batched_upload_patch",
          "signature": "(batch_size: int = 10)",
          "lineno": 12,
          "doc": "Perform install batched upload patch.\n\nArgs:\n    batch_size: Batch size controlling transfer or inference throughput.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n    "
        }
      ]
    },
    {
      "module": "src.dataset_tools.label_studio_json",
      "file": "src/dataset_tools/label_studio_json.py",
      "doc": "Implementation module for Label Studio integration.",
      "classes": [],
      "functions": [
        {
          "name": "build_tasks",
          "signature": "(root_dir: Path, ls_root: str)",
          "lineno": 10,
          "doc": "Build tasks for downstream steps.\n\nArgs:\n    root_dir: Root directory used by resolver or loader logic.\n    ls_root: Value controlling ls root for this routine.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n    "
        }
      ]
    },
    {
      "module": "src.dataset_tools.loader",
      "file": "src/dataset_tools/loader.py",
      "doc": "Implementation module for dataset loading.",
      "classes": [],
      "functions": [
        {
          "name": "import_yolo_dataset_from_root",
          "signature": "(root_dir: str, dataset_name: str, image_subdir: str = 'images', labels_subdir: str = 'labels', class_id_to_label: dict[int, str] | None = None, overwrite: bool = True)",
          "lineno": 17,
          "doc": "Perform import yolo dataset from root.\n\nArgs:\n    root_dir: Root directory used by resolver or loader logic.\n    dataset_name: Name of the FiftyOne dataset to operate on.\n    image_subdir: Value controlling image subdir for this routine.\n    labels_subdir: Value controlling labels subdir for this routine.\n    class_id_to_label: Value controlling class id to label for this routine.\n    overwrite: Whether existing resources should be replaced.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n    "
        },
        {
          "name": "import_yolo_dataset_from_roots",
          "signature": "(images_root: str, labels_root: str, dataset_name: str, class_id_to_label: dict[int, str] | None = None, overwrite: bool = True)",
          "lineno": 50,
          "doc": "Perform import yolo dataset from roots.\n\nArgs:\n    images_root: Value controlling images root for this routine.\n    labels_root: Value controlling labels root for this routine.\n    dataset_name: Name of the FiftyOne dataset to operate on.\n    class_id_to_label: Value controlling class id to label for this routine.\n    overwrite: Whether existing resources should be replaced.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n    "
        },
        {
          "name": "get_or_create_dataset",
          "signature": "(name: str)",
          "lineno": 77,
          "doc": "Perform get or create dataset.\n\nArgs:\n    name: Name identifier for the resource being created or retrieved.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n    "
        }
      ]
    },
    {
      "module": "src.dataset_tools.loaders",
      "file": "src/dataset_tools/loaders/__init__.py",
      "doc": "Package initializer for `dataset_tools.loaders`.",
      "classes": [],
      "functions": []
    },
    {
      "module": "src.dataset_tools.loaders.base",
      "file": "src/dataset_tools/loaders/base.py",
      "doc": "Implementation module for dataset loading.",
      "classes": [
        {
          "name": "LoaderResult",
          "lineno": 12,
          "doc": "LoaderResult used by dataset loading.\n    ",
          "methods": []
        },
        {
          "name": "BaseDatasetLoader",
          "lineno": 19,
          "doc": "Dataset loader that imports source media/annotations into FiftyOne.\n    ",
          "methods": [
            {
              "name": "load",
              "signature": "(self, dataset_name: str, overwrite: bool = False, persistent: bool = True) -> LoaderResult",
              "lineno": 24,
              "doc": "Perform load.\n\nArgs:\n    dataset_name: Name of the FiftyOne dataset to operate on.\n    overwrite: Whether existing resources should be replaced.\n    persistent: Whether created FiftyOne datasets should be persistent.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n        "
            },
            {
              "name": "_create_or_replace_dataset",
              "signature": "(name: str, overwrite: bool, persistent: bool)",
              "lineno": 38,
              "doc": "Internal helper for create or replace dataset.\n\nArgs:\n    name: Name identifier for the resource being created or retrieved.\n    overwrite: Whether existing resources should be replaced.\n    persistent: Whether created FiftyOne datasets should be persistent.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n        "
            }
          ]
        }
      ],
      "functions": []
    },
    {
      "module": "src.dataset_tools.loaders.coco",
      "file": "src/dataset_tools/loaders/coco.py",
      "doc": "Implementation module for dataset loading.",
      "classes": [
        {
          "name": "CocoLoaderConfig",
          "lineno": 14,
          "doc": "Configuration dataclass for dataset loading.\n    ",
          "methods": []
        },
        {
          "name": "CocoDatasetLoader",
          "lineno": 22,
          "doc": "Dataset loader that imports source media/annotations into FiftyOne.\n    ",
          "methods": [
            {
              "name": "__init__",
              "signature": "(self, config: CocoLoaderConfig)",
              "lineno": 25,
              "doc": "Initialize `CocoDatasetLoader` with runtime parameters.\n\nArgs:\n    config: Configuration object controlling runtime behavior.\n\nReturns:\n    None.\n        "
            },
            {
              "name": "load",
              "signature": "(self, dataset_name: str, overwrite: bool = False, persistent: bool = True) -> LoaderResult",
              "lineno": 36,
              "doc": "Perform load.\n\nArgs:\n    dataset_name: Name of the FiftyOne dataset to operate on.\n    overwrite: Whether existing resources should be replaced.\n    persistent: Whether created FiftyOne datasets should be persistent.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n        "
            }
          ]
        }
      ],
      "functions": []
    },
    {
      "module": "src.dataset_tools.loaders.path_resolvers",
      "file": "src/dataset_tools/loaders/path_resolvers.py",
      "doc": "Implementation module for dataset loading.",
      "classes": [
        {
          "name": "MirroredRootsPathResolver",
          "lineno": 11,
          "doc": "MirroredRootsPathResolver used by dataset loading.\n    ",
          "methods": [
            {
              "name": "label_path_for",
              "signature": "(self, image_path: Path) -> Path",
              "lineno": 18,
              "doc": "Perform label path for.\n\nArgs:\n    image_path: Value controlling image path for this routine.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n        "
            }
          ]
        },
        {
          "name": "ImagesLabelsSubdirResolver",
          "lineno": 32,
          "doc": "ImagesLabelsSubdirResolver used by dataset loading.\n    ",
          "methods": [
            {
              "name": "images_root",
              "signature": "(self) -> Path",
              "lineno": 41,
              "doc": "Perform images root.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n        "
            },
            {
              "name": "labels_root",
              "signature": "(self) -> Path",
              "lineno": 50,
              "doc": "Perform labels root.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n        "
            },
            {
              "name": "label_path_for",
              "signature": "(self, image_path: Path) -> Path",
              "lineno": 58,
              "doc": "Perform label path for.\n\nArgs:\n    image_path: Value controlling image path for this routine.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n        "
            }
          ]
        }
      ],
      "functions": [
        {
          "name": "default_image_filter",
          "signature": "(path: Path) -> bool",
          "lineno": 71,
          "doc": "Perform default image filter.\n\nArgs:\n    path: Filesystem path used for reading/writing artifacts.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n    "
        }
      ]
    },
    {
      "module": "src.dataset_tools.loaders.yolo",
      "file": "src/dataset_tools/loaders/yolo.py",
      "doc": "Implementation module for dataset loading.",
      "classes": [
        {
          "name": "YoloParserConfig",
          "lineno": 20,
          "doc": "Configuration dataclass for dataset loading.\n    ",
          "methods": []
        },
        {
          "name": "YoloDatasetLoader",
          "lineno": 27,
          "doc": "Dataset loader that imports source media/annotations into FiftyOne.\n    ",
          "methods": [
            {
              "name": "__init__",
              "signature": "(self, resolver: MirroredRootsPathResolver | ImagesLabelsSubdirResolver, parser_config: YoloParserConfig | None = None, image_filter: Callable[[Path], bool] = default_image_filter, sample_metadata_fields: dict[str, Callable[[Path], object]] | None = None)",
              "lineno": 30,
              "doc": "Initialize `YoloDatasetLoader` with runtime parameters.\n\nArgs:\n    resolver: Value controlling resolver for this routine.\n    parser_config: Value controlling parser config for this routine.\n    image_filter: Value controlling image filter for this routine.\n    sample_metadata_fields: Value controlling sample metadata fields for this routine.\n\nReturns:\n    None.\n        "
            },
            {
              "name": "load",
              "signature": "(self, dataset_name: str, overwrite: bool = False, persistent: bool = True) -> LoaderResult",
              "lineno": 53,
              "doc": "Perform load.\n\nArgs:\n    dataset_name: Name of the FiftyOne dataset to operate on.\n    overwrite: Whether existing resources should be replaced.\n    persistent: Whether created FiftyOne datasets should be persistent.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n        "
            },
            {
              "name": "_parse_yolo_file",
              "signature": "(self, label_path: Path)",
              "lineno": 87,
              "doc": "Parse and validate yolo file input values.\n\nArgs:\n    label_path: Value controlling label path for this routine.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n        "
            }
          ]
        }
      ],
      "functions": []
    },
    {
      "module": "src.dataset_tools.metrics",
      "file": "src/dataset_tools/metrics/__init__.py",
      "doc": "Package initializer for `dataset_tools.metrics`.",
      "classes": [],
      "functions": []
    },
    {
      "module": "src.dataset_tools.metrics.base",
      "file": "src/dataset_tools/metrics/base.py",
      "doc": "Implementation module for metric computation.",
      "classes": [
        {
          "name": "BaseMetricComputation",
          "lineno": 10,
          "doc": "BaseMetricComputation used by metric computation.\n    ",
          "methods": [
            {
              "name": "__init__",
              "signature": "(self, dataset_name: str)",
              "lineno": 13,
              "doc": "Initialize `BaseMetricComputation` with runtime parameters.\n\nArgs:\n    dataset_name: Name of the FiftyOne dataset to operate on.\n\nReturns:\n    None.\n        "
            },
            {
              "name": "load_dataset",
              "signature": "(self)",
              "lineno": 24,
              "doc": "Load dataset required by this module.\n\nReturns:\n    Loaded object/data required by downstream workflow steps.\n        "
            },
            {
              "name": "run",
              "signature": "(self)",
              "lineno": 34,
              "doc": "Run the operation and return execution results.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n        "
            },
            {
              "name": "compute",
              "signature": "(self, dataset)",
              "lineno": 44,
              "doc": "Perform compute.\n\nArgs:\n    dataset: FiftyOne dataset or dataset-like collection used by this operation.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n        "
            }
          ]
        }
      ],
      "functions": []
    },
    {
      "module": "src.dataset_tools.metrics.embeddings",
      "file": "src/dataset_tools/metrics/embeddings.py",
      "doc": "Implementation module for metric computation.",
      "classes": [
        {
          "name": "EmbeddingsComputation",
          "lineno": 15,
          "doc": "EmbeddingsComputation used by metric computation.\n    ",
          "methods": [
            {
              "name": "__init__",
              "signature": "(self, dataset_name: str, model_name: str = 'facebook/dinov2-base', model_ref: str | None = None, embeddings_field: str = 'embeddings', patches_field: str | None = None, use_umap: bool = True, use_cluster: bool = True, n_clusters: int = 10)",
              "lineno": 18,
              "doc": "Initialize `EmbeddingsComputation` with runtime parameters.\n\nArgs:\n    dataset_name: Name of the FiftyOne dataset to operate on.\n    model_name: Model identifier used by the selected backend.\n    model_ref: Provider-qualified model reference (for example `hf:...`, `foz:...`, `anomalib:...`).\n    embeddings_field: Field containing embeddings vectors.\n    patches_field: Value controlling patches field for this routine.\n    use_umap: Value controlling use umap for this routine.\n    use_cluster: Value controlling use cluster for this routine.\n    n_clusters: Value controlling n clusters for this routine.\n\nReturns:\n    None.\n        "
            },
            {
              "name": "compute",
              "signature": "(self, dataset)",
              "lineno": 53,
              "doc": "Perform compute.\n\nArgs:\n    dataset: FiftyOne dataset or dataset-like collection used by this operation.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n        "
            }
          ]
        }
      ],
      "functions": []
    },
    {
      "module": "src.dataset_tools.metrics.field_metric",
      "file": "src/dataset_tools/metrics/field_metric.py",
      "doc": "Implementation module for metric computation.",
      "classes": [
        {
          "name": "FieldMetricComputation",
          "lineno": 12,
          "doc": "FieldMetricComputation used by metric computation.\n    ",
          "methods": [
            {
              "name": "__init__",
              "signature": "(self, dataset_name: str, required_fields: Iterable[str] | None = None)",
              "lineno": 16,
              "doc": "Initialize `FieldMetricComputation` with runtime parameters.\n\nArgs:\n    dataset_name: Name of the FiftyOne dataset to operate on.\n    required_fields: Value controlling required fields for this routine.\n\nReturns:\n    None.\n        "
            },
            {
              "name": "validate_required_fields",
              "signature": "(self, dataset)",
              "lineno": 29,
              "doc": "Perform validate required fields.\n\nArgs:\n    dataset: FiftyOne dataset or dataset-like collection used by this operation.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n        "
            },
            {
              "name": "run",
              "signature": "(self)",
              "lineno": 45,
              "doc": "Run the operation and return execution results.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n        "
            },
            {
              "name": "compute",
              "signature": "(self, dataset) -> Any",
              "lineno": 59,
              "doc": "Perform compute.\n\nArgs:\n    dataset: FiftyOne dataset or dataset-like collection used by this operation.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n        "
            }
          ]
        }
      ],
      "functions": []
    },
    {
      "module": "src.dataset_tools.metrics.hardness",
      "file": "src/dataset_tools/metrics/hardness.py",
      "doc": "Implementation module for metric computation.",
      "classes": [
        {
          "name": "HardnessComputation",
          "lineno": 11,
          "doc": "HardnessComputation used by metric computation.\n    ",
          "methods": [
            {
              "name": "__init__",
              "signature": "(self, dataset_name: str, label_field: str = 'ground_truth', output_field: str = 'hardness')",
              "lineno": 14,
              "doc": "Initialize `HardnessComputation` with runtime parameters.\n\nArgs:\n    dataset_name: Name of the FiftyOne dataset to operate on.\n    label_field: Field name containing labels for this operation.\n    output_field: Field name where this operation stores its output.\n\nReturns:\n    None.\n        "
            },
            {
              "name": "compute",
              "signature": "(self, dataset)",
              "lineno": 34,
              "doc": "Perform compute.\n\nArgs:\n    dataset: FiftyOne dataset or dataset-like collection used by this operation.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n        "
            }
          ]
        }
      ],
      "functions": []
    },
    {
      "module": "src.dataset_tools.metrics.mistakenness",
      "file": "src/dataset_tools/metrics/mistakenness.py",
      "doc": "Implementation module for metric computation.",
      "classes": [
        {
          "name": "MistakennessComputation",
          "lineno": 10,
          "doc": "MistakennessComputation used by metric computation.\n    ",
          "methods": [
            {
              "name": "__init__",
              "signature": "(self, dataset_name: str, pred_field: str = 'predictions', gt_field: str = 'ground_truth', mistakenness_field: str = 'mistakenness', missing_field: str = 'possible_missing', spurious_field: str = 'possible_spurious')",
              "lineno": 13,
              "doc": "Initialize `MistakennessComputation` with runtime parameters.\n\nArgs:\n    dataset_name: Name of the FiftyOne dataset to operate on.\n    pred_field: Prediction field name used as input.\n    gt_field: Ground-truth field name used as input.\n    mistakenness_field: Value controlling mistakenness field for this routine.\n    missing_field: Value controlling missing field for this routine.\n    spurious_field: Value controlling spurious field for this routine.\n\nReturns:\n    None.\n        "
            },
            {
              "name": "compute",
              "signature": "(self, dataset)",
              "lineno": 42,
              "doc": "Perform compute.\n\nArgs:\n    dataset: FiftyOne dataset or dataset-like collection used by this operation.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n        "
            }
          ]
        }
      ],
      "functions": []
    },
    {
      "module": "src.dataset_tools.metrics.representativeness",
      "file": "src/dataset_tools/metrics/representativeness.py",
      "doc": "Implementation module for metric computation.",
      "classes": [
        {
          "name": "RepresentativenessComputation",
          "lineno": 10,
          "doc": "RepresentativenessComputation used by metric computation.\n    ",
          "methods": [
            {
              "name": "__init__",
              "signature": "(self, dataset_name: str, output_field: str = 'representativeness', method: str = 'cluster-center', embeddings_field: str | None = None, roi_field: str | None = None)",
              "lineno": 15,
              "doc": "Initialize `RepresentativenessComputation` with runtime parameters.\n\nArgs:\n    dataset_name: Name of the FiftyOne dataset to operate on.\n    output_field: Field name where this operation stores its output.\n    method: Value controlling method for this routine.\n    embeddings_field: Field containing embeddings vectors.\n    roi_field: Value controlling roi field for this routine.\n\nReturns:\n    None.\n        "
            },
            {
              "name": "compute",
              "signature": "(self, dataset)",
              "lineno": 46,
              "doc": "Perform compute.\n\nArgs:\n    dataset: FiftyOne dataset or dataset-like collection used by this operation.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n        "
            }
          ]
        }
      ],
      "functions": []
    },
    {
      "module": "src.dataset_tools.metrics.uniqueness",
      "file": "src/dataset_tools/metrics/uniqueness.py",
      "doc": "Implementation module for metric computation.",
      "classes": [
        {
          "name": "UniquenessComputation",
          "lineno": 10,
          "doc": "UniquenessComputation used by metric computation.\n    ",
          "methods": [
            {
              "name": "__init__",
              "signature": "(self, dataset_name: str, embeddings_field: str | None = None, output_field: str = 'uniqueness')",
              "lineno": 13,
              "doc": "Initialize `UniquenessComputation` with runtime parameters.\n\nArgs:\n    dataset_name: Name of the FiftyOne dataset to operate on.\n    embeddings_field: Field containing embeddings vectors.\n    output_field: Field name where this operation stores its output.\n\nReturns:\n    None.\n        "
            },
            {
              "name": "compute",
              "signature": "(self, dataset)",
              "lineno": 29,
              "doc": "Perform compute.\n\nArgs:\n    dataset: FiftyOne dataset or dataset-like collection used by this operation.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n        "
            }
          ]
        }
      ],
      "functions": []
    },
    {
      "module": "src.dataset_tools.models",
      "file": "src/dataset_tools/models/__init__.py",
      "doc": "Package initializer for `dataset_tools.models`.",
      "classes": [],
      "functions": []
    },
    {
      "module": "src.dataset_tools.models.base",
      "file": "src/dataset_tools/models/base.py",
      "doc": "Implementation module for model provider registry.",
      "classes": [
        {
          "name": "ModelProvider",
          "lineno": 11,
          "doc": "Model provider adapter that resolves and loads backend-specific models.\n    ",
          "methods": [
            {
              "name": "load",
              "signature": "(self, model_ref: ModelRef, *, task: str | None = None, **kwargs: Any) -> LoadedModel",
              "lineno": 17,
              "doc": "Perform load.\n\nArgs:\n    model_ref: Provider-qualified model reference (for example `hf:...`, `foz:...`, `anomalib:...`).\n    task: Value controlling task for this routine.\n    **kwargs: Additional keyword arguments forwarded to downstream APIs.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n        "
            },
            {
              "name": "list_models",
              "signature": "(self, contains: str | None = None, limit: int | None = None) -> list[str]",
              "lineno": 30,
              "doc": "List available models.\n\nArgs:\n    contains: Value controlling contains for this routine.\n    limit: Value controlling limit for this routine.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n        "
            }
          ]
        }
      ],
      "functions": []
    },
    {
      "module": "src.dataset_tools.models.providers",
      "file": "src/dataset_tools/models/providers/__init__.py",
      "doc": "Package initializer for `dataset_tools.models.providers`.",
      "classes": [],
      "functions": []
    },
    {
      "module": "src.dataset_tools.models.providers.anomalib",
      "file": "src/dataset_tools/models/providers/anomalib.py",
      "doc": "Implementation module for model provider registry.",
      "classes": [
        {
          "name": "AnomalibProvider",
          "lineno": 18,
          "doc": "Model provider adapter that resolves and loads backend-specific models.\n    ",
          "methods": [
            {
              "name": "_import_anomalib",
              "signature": "(self)",
              "lineno": 23,
              "doc": "Internal helper for import anomalib.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n        "
            },
            {
              "name": "load",
              "signature": "(self, model_ref: ModelRef, *, task: str | None = None, **kwargs: Any) -> LoadedModel",
              "lineno": 39,
              "doc": "Perform load.\n\nArgs:\n    model_ref: Provider-qualified model reference (for example `hf:...`, `foz:...`, `anomalib:...`).\n    task: Value controlling task for this routine.\n    **kwargs: Additional keyword arguments forwarded to downstream APIs.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n        "
            },
            {
              "name": "list_models",
              "signature": "(self, contains: str | None = None, limit: int | None = None) -> list[str]",
              "lineno": 101,
              "doc": "List available models.\n\nArgs:\n    contains: Value controlling contains for this routine.\n    limit: Value controlling limit for this routine.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n        "
            }
          ]
        }
      ],
      "functions": []
    },
    {
      "module": "src.dataset_tools.models.providers.fiftyone_zoo",
      "file": "src/dataset_tools/models/providers/fiftyone_zoo.py",
      "doc": "Implementation module for model provider registry.",
      "classes": [
        {
          "name": "FiftyOneZooProvider",
          "lineno": 13,
          "doc": "Model provider adapter that resolves and loads backend-specific models.\n    ",
          "methods": [
            {
              "name": "load",
              "signature": "(self, model_ref: ModelRef, *, task: str | None = None, **kwargs: Any) -> LoadedModel",
              "lineno": 18,
              "doc": "Perform load.\n\nArgs:\n    model_ref: Provider-qualified model reference (for example `hf:...`, `foz:...`, `anomalib:...`).\n    task: Value controlling task for this routine.\n    **kwargs: Additional keyword arguments forwarded to downstream APIs.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n        "
            },
            {
              "name": "list_models",
              "signature": "(self, contains: str | None = None, limit: int | None = None) -> list[str]",
              "lineno": 45,
              "doc": "List available models.\n\nArgs:\n    contains: Value controlling contains for this routine.\n    limit: Value controlling limit for this routine.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n        "
            }
          ]
        }
      ],
      "functions": []
    },
    {
      "module": "src.dataset_tools.models.providers.huggingface",
      "file": "src/dataset_tools/models/providers/huggingface.py",
      "doc": "Implementation module for model provider registry.",
      "classes": [
        {
          "name": "HuggingFaceEmbeddingModel",
          "lineno": 18,
          "doc": "HuggingFaceEmbeddingModel used by model provider registry.\n    ",
          "methods": [
            {
              "name": "__init__",
              "signature": "(self, model_name: str)",
              "lineno": 21,
              "doc": "Initialize `HuggingFaceEmbeddingModel` with runtime parameters.\n\nArgs:\n    model_name: Model identifier used by the selected backend.\n\nReturns:\n    None.\n        "
            },
            {
              "name": "media_type",
              "signature": "(self)",
              "lineno": 36,
              "doc": "Perform media type.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n        "
            },
            {
              "name": "has_embeddings",
              "signature": "(self)",
              "lineno": 45,
              "doc": "Perform has embeddings.\n\nReturns:\n    Boolean indicating the evaluated condition.\n        "
            },
            {
              "name": "embed",
              "signature": "(self, arg)",
              "lineno": 53,
              "doc": "Perform embed.\n\nArgs:\n    arg: Value controlling arg for this routine.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n        "
            },
            {
              "name": "embed_all",
              "signature": "(self, args)",
              "lineno": 82,
              "doc": "Perform embed all.\n\nArgs:\n    args: Value controlling args for this routine.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n        "
            }
          ]
        },
        {
          "name": "HuggingFaceProvider",
          "lineno": 94,
          "doc": "Model provider adapter that resolves and loads backend-specific models.\n    ",
          "methods": [
            {
              "name": "load",
              "signature": "(self, model_ref: ModelRef, *, task: str | None = None, **kwargs: Any) -> LoadedModel",
              "lineno": 99,
              "doc": "Perform load.\n\nArgs:\n    model_ref: Provider-qualified model reference (for example `hf:...`, `foz:...`, `anomalib:...`).\n    task: Value controlling task for this routine.\n    **kwargs: Additional keyword arguments forwarded to downstream APIs.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n        "
            }
          ]
        }
      ],
      "functions": []
    },
    {
      "module": "src.dataset_tools.models.registry",
      "file": "src/dataset_tools/models/registry.py",
      "doc": "Implementation module for model provider registry.",
      "classes": [],
      "functions": [
        {
          "name": "_provider_instances",
          "signature": "() -> dict[str, ModelProvider]",
          "lineno": 14,
          "doc": "Internal helper for provider instances.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n    "
        },
        {
          "name": "list_providers",
          "signature": "() -> list[str]",
          "lineno": 27,
          "doc": "List available providers.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n    "
        },
        {
          "name": "get_provider",
          "signature": "(name: str) -> ModelProvider",
          "lineno": 36,
          "doc": "Perform get provider.\n\nArgs:\n    name: Name identifier for the resource being created or retrieved.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n    "
        },
        {
          "name": "resolve_model_ref",
          "signature": "(raw: str, default_provider: str = 'hf') -> ModelRef",
          "lineno": 50,
          "doc": "Resolve model ref from provided inputs.\n\nArgs:\n    raw: Raw text value from input/CLI that will be parsed.\n    default_provider: Value controlling default provider for this routine.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n    "
        },
        {
          "name": "load_model",
          "signature": "(raw_model_ref: str, *, default_provider: str = 'hf', task: str | None = None, capability: str | None = None, **kwargs: Any) -> LoadedModel",
          "lineno": 63,
          "doc": "Load model required by this module.\n\nArgs:\n    raw_model_ref: Value controlling raw model ref for this routine.\n    default_provider: Value controlling default provider for this routine.\n    task: Value controlling task for this routine.\n    capability: Value controlling capability for this routine.\n    **kwargs: Additional keyword arguments forwarded to downstream APIs.\n\nReturns:\n    Loaded object/data required by downstream workflow steps.\n    "
        },
        {
          "name": "provider_model_list",
          "signature": "(provider_name: str, *, contains: str | None = None, limit: int | None = None) -> list[str]",
          "lineno": 97,
          "doc": "Perform provider model list.\n\nArgs:\n    provider_name: Value controlling provider name for this routine.\n    contains: Value controlling contains for this routine.\n    limit: Value controlling limit for this routine.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n    "
        }
      ]
    },
    {
      "module": "src.dataset_tools.models.spec",
      "file": "src/dataset_tools/models/spec.py",
      "doc": "Implementation module for model provider registry.",
      "classes": [
        {
          "name": "ModelRef",
          "lineno": 21,
          "doc": "ModelRef used by model provider registry.\n    ",
          "methods": []
        },
        {
          "name": "LoadedModel",
          "lineno": 30,
          "doc": "LoadedModel used by model provider registry.\n    ",
          "methods": [
            {
              "name": "supports",
              "signature": "(self, capability: str | None) -> bool",
              "lineno": 38,
              "doc": "Perform supports.\n\nArgs:\n    capability: Value controlling capability for this routine.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n        "
            }
          ]
        }
      ],
      "functions": [
        {
          "name": "normalize_provider",
          "signature": "(provider: str) -> str",
          "lineno": 52,
          "doc": "Perform normalize provider.\n\nArgs:\n    provider: Value controlling provider for this routine.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n    "
        },
        {
          "name": "parse_model_ref",
          "signature": "(raw: str, default_provider: str = 'hf') -> ModelRef",
          "lineno": 70,
          "doc": "Parse and normalize model ref.\n\nArgs:\n    raw: Raw text value from input/CLI that will be parsed.\n    default_provider: Value controlling default provider for this routine.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n    "
        }
      ]
    },
    {
      "module": "src.dataset_tools.sync_from_fo_to_disk",
      "file": "src/dataset_tools/sync_from_fo_to_disk.py",
      "doc": "Implementation module for dataset tools runtime.",
      "classes": [],
      "functions": [
        {
          "name": "backup_file",
          "signature": "(filepath: str, suffix_format: str = '%Y%m%d_%H%M%S') -> str | None",
          "lineno": 13,
          "doc": "Perform backup file.\n\nArgs:\n    filepath: Filesystem path to a file.\n    suffix_format: Value controlling suffix format for this routine.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n    "
        },
        {
          "name": "infer_label_path",
          "signature": "(image_path: str, path_replacements: Iterable[tuple[str, str]]) -> str | None",
          "lineno": 32,
          "doc": "Perform infer label path.\n\nArgs:\n    image_path: Value controlling image path for this routine.\n    path_replacements: Ordered path replacement rules used for path translation.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n    "
        },
        {
          "name": "sync_corrections_to_disk",
          "signature": "(dataset_name: str | None = None, dry_run: bool = False, tag_filter: str | None = None, corrections_field: str | None = None, label_to_class_id: dict[str, int] | None = None, default_class_id: int | None = None, path_replacements: Iterable[tuple[str, str]] | None = None, backup_suffix_format: str | None = None) -> int",
          "lineno": 51,
          "doc": "Perform sync corrections to disk.\n\nArgs:\n    dataset_name: Name of the FiftyOne dataset to operate on.\n    dry_run: If true, report actions without writing changes.\n    tag_filter: Sample tag filter used to restrict processing scope.\n    corrections_field: Field containing corrected annotations.\n    label_to_class_id: Mapping from label string to YOLO class id integer.\n    default_class_id: Fallback class id used when mapping is missing a label.\n    path_replacements: Ordered path replacement rules used for path translation.\n    backup_suffix_format: strftime format used when creating backup filenames.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n    "
        }
      ]
    },
    {
      "module": "src.dataset_tools.tag_workflow",
      "file": "src/dataset_tools/tag_workflow/__init__.py",
      "doc": "Package initializer for `dataset_tools.tag_workflow`.",
      "classes": [],
      "functions": []
    },
    {
      "module": "src.dataset_tools.tag_workflow.config",
      "file": "src/dataset_tools/tag_workflow/config.py",
      "doc": "Implementation module for tag workflow execution.",
      "classes": [
        {
          "name": "TagOperationRule",
          "lineno": 10,
          "doc": "TagOperationRule used by tag workflow execution.\n    ",
          "methods": []
        },
        {
          "name": "TagWorkflowConfig",
          "lineno": 19,
          "doc": "Configuration dataclass for tag workflow execution.\n    ",
          "methods": []
        }
      ],
      "functions": []
    },
    {
      "module": "src.dataset_tools.tag_workflow.context",
      "file": "src/dataset_tools/tag_workflow/context.py",
      "doc": "Implementation module for tag workflow execution.",
      "classes": [
        {
          "name": "TagWorkflowContext",
          "lineno": 12,
          "doc": "TagWorkflowContext used by tag workflow execution.\n    ",
          "methods": []
        }
      ],
      "functions": []
    },
    {
      "module": "src.dataset_tools.tag_workflow.engine",
      "file": "src/dataset_tools/tag_workflow/engine.py",
      "doc": "Implementation module for tag workflow execution.",
      "classes": [
        {
          "name": "TagWorkflowEngine",
          "lineno": 15,
          "doc": "TagWorkflowEngine used by tag workflow execution.\n    ",
          "methods": [
            {
              "name": "__init__",
              "signature": "(self, app_config: AppConfig, operations: dict[str, Any] | None = None)",
              "lineno": 18,
              "doc": "Initialize `TagWorkflowEngine` with runtime parameters.\n\nArgs:\n    app_config: Resolved `AppConfig` instance.\n    operations: Value controlling operations for this routine.\n\nReturns:\n    None.\n        "
            },
            {
              "name": "register_operation",
              "signature": "(self, name: str, operation)",
              "lineno": 31,
              "doc": "Perform register operation.\n\nArgs:\n    name: Name identifier for the resource being created or retrieved.\n    operation: Value controlling operation for this routine.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n        "
            },
            {
              "name": "run",
              "signature": "(self, workflow_config: TagWorkflowConfig) -> list[dict[str, Any]]",
              "lineno": 43,
              "doc": "Run the operation and return execution results.\n\nArgs:\n    workflow_config: Value controlling workflow config for this routine.\n\nReturns:\n    Result object consumed by the caller or downstream workflow.\n        "
            }
          ]
        }
      ],
      "functions": []
    },
    {
      "module": "src.dataset_tools.tag_workflow.operations",
      "file": "src/dataset_tools/tag_workflow/operations/__init__.py",
      "doc": "Package initializer for `dataset_tools.tag_workflow.operations`.",
      "classes": [],
      "functions": []
    },
    {
      "module": "src.dataset_tools.tag_workflow.operations.analysis",
      "file": "src/dataset_tools/tag_workflow/operations/analysis.py",
      "doc": "Analysis-focused tag-workflow operations.\n\nThese operations compute FiftyOne brain/metric/anomaly outputs and are wired\ninto the same rule engine as core mutation/sync operations.",
      "classes": [
        {
          "name": "ComputeUniquenessOperation",
          "lineno": 64,
          "doc": "Compute uniqueness scores for samples in view or dataset scope.",
          "methods": [
            {
              "name": "execute",
              "signature": "(self, context: TagWorkflowContext, view: Any, params: dict[str, Any], tag: str | None)",
              "lineno": 68,
              "doc": "Compute and store uniqueness field via ``fiftyone.brain.compute_uniqueness``."
            }
          ]
        },
        {
          "name": "ComputeHardnessOperation",
          "lineno": 108,
          "doc": "Compute hardness for classification-style fields.",
          "methods": [
            {
              "name": "execute",
              "signature": "(self, context: TagWorkflowContext, view: Any, params: dict[str, Any], tag: str | None)",
              "lineno": 112,
              "doc": "Validate label type and compute hardness scores for target scope."
            }
          ]
        },
        {
          "name": "ComputeRepresentativenessOperation",
          "lineno": 161,
          "doc": "Compute representativeness metrics with optional embeddings/ROI settings.",
          "methods": [
            {
              "name": "execute",
              "signature": "(self, context: TagWorkflowContext, view: Any, params: dict[str, Any], tag: str | None)",
              "lineno": 165,
              "doc": "Compute representativeness and enforce clustering prerequisites."
            }
          ]
        },
        {
          "name": "ComputeSimilarityIndexOperation",
          "lineno": 219,
          "doc": "Compute dataset-level similarity index (brain run).",
          "methods": [
            {
              "name": "execute",
              "signature": "(self, context: TagWorkflowContext, view: Any, params: dict[str, Any], tag: str | None)",
              "lineno": 223,
              "doc": "Run ``fob.compute_similarity`` with optional embeddings/backend settings."
            }
          ]
        },
        {
          "name": "ComputeExactDuplicatesOperation",
          "lineno": 254,
          "doc": "Compute exact-duplicate summary statistics at dataset scope.",
          "methods": [
            {
              "name": "execute",
              "signature": "(self, context: TagWorkflowContext, view: Any, params: dict[str, Any], tag: str | None)",
              "lineno": 258,
              "doc": "Run exact duplicate detection and return aggregate counts."
            }
          ]
        },
        {
          "name": "ComputeNearDuplicatesOperation",
          "lineno": 288,
          "doc": "Compute near-duplicate relationships and summary counts.",
          "methods": [
            {
              "name": "execute",
              "signature": "(self, context: TagWorkflowContext, view: Any, params: dict[str, Any], tag: str | None)",
              "lineno": 292,
              "doc": "Run near-duplicate search and summarize affected samples/pairs."
            }
          ]
        },
        {
          "name": "ComputeLeakySplitsOperation",
          "lineno": 334,
          "doc": "Detect potential train/val/test leakage across configured splits.",
          "methods": [
            {
              "name": "execute",
              "signature": "(self, context: TagWorkflowContext, view: Any, params: dict[str, Any], tag: str | None)",
              "lineno": 338,
              "doc": "Run leaky-split detection and return leakage summary payload."
            }
          ]
        },
        {
          "name": "ComputeAnomalyScoresOperation",
          "lineno": 387,
          "doc": "Compute anomaly scores via embedding-distance or anomalib artifact backend.",
          "methods": [
            {
              "name": "execute",
              "signature": "(self, context: TagWorkflowContext, view: Any, params: dict[str, Any], tag: str | None)",
              "lineno": 391,
              "doc": "Dispatch anomaly scoring to selected backend and return backend payload.\n\nBackend options:\n- ``embedding_distance``: fit reference from embeddings and score distance\n- ``anomalib``: score with provided exported artifact"
            }
          ]
        }
      ],
      "functions": [
        {
          "name": "_resolve_scope_collection",
          "signature": "(context: TagWorkflowContext, view: Any, params: dict[str, Any], *, operation: str, default_scope: str) -> tuple[Any, str]",
          "lineno": 23,
          "doc": "Resolve whether an operation should run on the full dataset or current view.\n\nSupported scope values:\n- ``dataset``: run against ``context.dataset``\n- ``view``: run against rule-selected ``view``"
        },
        {
          "name": "_require_dataset_scope",
          "signature": "(params: dict[str, Any], operation: str)",
          "lineno": 47,
          "doc": "Enforce dataset-global scope for operations that cannot run on a view."
        },
        {
          "name": "_ensure_sample_field",
          "signature": "(collection: Any, field: str, dataset_name: str)",
          "lineno": 56,
          "doc": "Raise if ``field`` is missing on target sample collection."
        }
      ]
    },
    {
      "module": "src.dataset_tools.tag_workflow.operations.base",
      "file": "src/dataset_tools/tag_workflow/operations/base.py",
      "doc": "Base operation contract for tag-workflow actions.",
      "classes": [
        {
          "name": "TagOperation",
          "lineno": 10,
          "doc": "Abstract interface implemented by all tag-workflow operations.",
          "methods": [
            {
              "name": "execute",
              "signature": "(self, context: TagWorkflowContext, view: Any, params: dict[str, Any], tag: str | None) -> dict[str, Any]",
              "lineno": 15,
              "doc": "Execute operation logic for the selected tag/view scope.\n\nArgs:\n    context: Shared workflow context (dataset, config, caches).\n    view: FiftyOne view selected by the current rule/tag.\n    params: Rule-specific parameters.\n    tag: Tag value associated with the rule (or ``None``).\n\nReturns:\n    JSON-serializable result payload for workflow reporting."
            }
          ]
        }
      ],
      "functions": []
    },
    {
      "module": "src.dataset_tools.tag_workflow.operations.core",
      "file": "src/dataset_tools/tag_workflow/operations/core.py",
      "doc": "Core tag-workflow operations for mutation, LS sync, and disk sync.\n\nThese operations are intentionally dataset-agnostic and receive behavior through\nrule parameters, which keeps project-specific logic out of reusable tooling.",
      "classes": [
        {
          "name": "DeleteSamplesOperation",
          "lineno": 77,
          "doc": "Delete selected samples from the active dataset.",
          "methods": [
            {
              "name": "execute",
              "signature": "(self, context: TagWorkflowContext, view: Any, params: dict[str, Any], tag: str | None)",
              "lineno": 81,
              "doc": "Delete all samples in ``view`` and report count."
            }
          ]
        },
        {
          "name": "DeleteFilesAndSamplesOperation",
          "lineno": 88,
          "doc": "Delete media files on disk and then delete corresponding samples.",
          "methods": [
            {
              "name": "execute",
              "signature": "(self, context: TagWorkflowContext, view: Any, params: dict[str, Any], tag: str | None)",
              "lineno": 92,
              "doc": "Remove existing files referenced by ``view`` and drop samples."
            }
          ]
        },
        {
          "name": "MoveSamplesToDatasetOperation",
          "lineno": 110,
          "doc": "Copy/move selected samples into a target dataset.",
          "methods": [
            {
              "name": "execute",
              "signature": "(self, context: TagWorkflowContext, view: Any, params: dict[str, Any], tag: str | None)",
              "lineno": 114,
              "doc": "Add ``view`` samples to target dataset and optionally remove source samples.\n\nRequired params:\n    - ``target_dataset``: target dataset name\n\nOptional params:\n    - ``remove_from_source`` (default ``True``)"
            }
          ]
        },
        {
          "name": "SendToLabelStudioOperation",
          "lineno": 147,
          "doc": "Send selected samples to Label Studio using configured upload strategy.",
          "methods": [
            {
              "name": "execute",
              "signature": "(self, context: TagWorkflowContext, view: Any, params: dict[str, Any], tag: str | None)",
              "lineno": 151,
              "doc": "Push samples to LS and return transfer diagnostics.\n\nStrategy options:\n    - ``sdk_batched``: direct SDK task import (preferred default)\n    - ``annotate_batched``: FiftyOne annotate backend with annotation runs"
            }
          ]
        },
        {
          "name": "PullFromLabelStudioOperation",
          "lineno": 223,
          "doc": "Pull submitted LS annotations back into FiftyOne correction fields.",
          "methods": [
            {
              "name": "execute",
              "signature": "(self, context: TagWorkflowContext, view: Any, params: dict[str, Any], tag: str | None)",
              "lineno": 227,
              "doc": "Pull LS annotations using strategy-compatible mapping path.\n\nPull strategy defaults by upload strategy:\n    - annotate upload -> ``annotate_run`` pull\n    - sdk upload -> ``sdk_meta`` pull"
            }
          ]
        },
        {
          "name": "SyncCorrectionsToDiskOperation",
          "lineno": 288,
          "doc": "Write correction fields from FiftyOne samples back to label files on disk.",
          "methods": [
            {
              "name": "execute",
              "signature": "(self, context: TagWorkflowContext, view: Any, params: dict[str, Any], tag: str | None)",
              "lineno": 292,
              "doc": "Run disk sync with workflow/config overrides and report synced file count."
            }
          ]
        }
      ],
      "functions": [
        {
          "name": "_app_config_with_ls_overrides",
          "signature": "(config: AppConfig, params: dict[str, Any]) -> AppConfig",
          "lineno": 41,
          "doc": "Return config copy with optional Label Studio/dataset overrides from rule params.\n\nSupported keys in ``params`` are mapped onto ``AppConfig.label_studio`` and\nselected dataset sync fields so a single workflow can target different LS\nprojects/storages without mutating global config."
        },
        {
          "name": "default_operations_registry",
          "signature": "() -> dict[str, TagOperation]",
          "lineno": 317,
          "doc": "Return default registry of core and analysis operations by operation name."
        }
      ]
    },
    {
      "module": "src.dataset_tools.tools",
      "file": "src/dataset_tools/tools/__init__.py",
      "doc": "Package initializer for `dataset_tools.tools`.",
      "classes": [],
      "functions": []
    },
    {
      "module": "src.dataset_tools.workflows",
      "file": "src/dataset_tools/workflows/__init__.py",
      "doc": "Package initializer for `dataset_tools.workflows`.",
      "classes": [],
      "functions": []
    },
    {
      "module": "src.dataset_tools.workflows.roundtrip",
      "file": "src/dataset_tools/workflows/roundtrip.py",
      "doc": "High-level orchestration for FiftyOne <-> Label Studio curation roundtrip.\n\nThe roundtrip workflow composes three operations:\n\n1. send tagged samples to Label Studio\n2. pull submitted annotations back into FiftyOne\n3. optionally sync corrected labels back to disk",
      "classes": [
        {
          "name": "RoundtripWorkflowConfig",
          "lineno": 19,
          "doc": "Configuration for a single roundtrip execution.\n\nThis object captures both control flags (which stages to run) and\nstage-specific parameter dictionaries that are forwarded into underlying\ntag-workflow operations.",
          "methods": []
        },
        {
          "name": "CurationRoundtripWorkflow",
          "lineno": 42,
          "doc": "Build and execute roundtrip workflows via the tag-workflow engine.",
          "methods": [
            {
              "name": "__init__",
              "signature": "(self, app_config: AppConfig)",
              "lineno": 45,
              "doc": "Create a roundtrip workflow runner bound to resolved app config.\n\nArgs:\n    app_config: Resolved application config used by all workflow stages."
            },
            {
              "name": "run",
              "signature": "(self, config: RoundtripWorkflowConfig) -> list[dict[str, Any]]",
              "lineno": 54,
              "doc": "Build stage rules from ``config`` and execute them in order.\n\nRule order is deterministic:\n- ``send_to_label_studio`` (optional)\n- ``pull_from_label_studio`` (optional)\n- ``sync_corrections_to_disk`` (optional)\n\nArgs:\n    config: Roundtrip run configuration.\n\nReturns:\n    Ordered list of operation result payloads from the workflow engine."
            }
          ]
        }
      ],
      "functions": []
    }
  ],
  "cli": {
    "path": [],
    "prog": "dst",
    "description": "Dataset Tools CLI",
    "handler": null,
    "handler_doc": null,
    "positionals": [],
    "options": [],
    "subcommands": {
      "config": {
        "path": [
          "config"
        ],
        "prog": "dst config",
        "description": null,
        "handler": null,
        "handler_doc": null,
        "positionals": [],
        "options": [],
        "subcommands": {
          "show": {
            "path": [
              "config",
              "show"
            ],
            "prog": "dst config show",
            "description": null,
            "handler": "cmd_config_show",
            "handler_doc": "Run the `dst config show` command handler and return a JSON-serializable result.",
            "positionals": [],
            "options": [
              {
                "option_strings": [
                  "--config"
                ],
                "dest": "config",
                "required": false,
                "default": null,
                "help": "Path to local config JSON (otherwise DST_CONFIG_PATH, package-local file, or ~/.config/dst/local_config.json)",
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--overrides"
                ],
                "dest": "overrides",
                "required": false,
                "default": null,
                "help": "JSON object with runtime config overrides",
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--show-secrets"
                ],
                "dest": "show_secrets",
                "required": false,
                "default": false,
                "help": "Do not mask sensitive fields",
                "choices": null,
                "metavar": null,
                "nargs": 0
              }
            ],
            "subcommands": {}
          }
        }
      },
      "ls": {
        "path": [
          "ls"
        ],
        "prog": "dst ls",
        "description": null,
        "handler": null,
        "handler_doc": null,
        "positionals": [],
        "options": [],
        "subcommands": {
          "test": {
            "path": [
              "ls",
              "test"
            ],
            "prog": "dst ls test",
            "description": null,
            "handler": "cmd_ls_test",
            "handler_doc": "Run the `dst ls test` command handler and return a JSON-serializable result.",
            "positionals": [],
            "options": [
              {
                "option_strings": [
                  "--config"
                ],
                "dest": "config",
                "required": false,
                "default": null,
                "help": "Path to local config JSON (otherwise DST_CONFIG_PATH, package-local file, or ~/.config/dst/local_config.json)",
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--overrides"
                ],
                "dest": "overrides",
                "required": false,
                "default": null,
                "help": "JSON object with runtime config overrides",
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--list-projects"
                ],
                "dest": "list_projects",
                "required": false,
                "default": false,
                "help": "Include project list in output",
                "choices": null,
                "metavar": null,
                "nargs": 0
              }
            ],
            "subcommands": {}
          },
          "project": {
            "path": [
              "ls",
              "project"
            ],
            "prog": "dst ls project",
            "description": null,
            "handler": null,
            "handler_doc": null,
            "positionals": [],
            "options": [],
            "subcommands": {
              "list": {
                "path": [
                  "ls",
                  "project",
                  "list"
                ],
                "prog": "dst ls project list",
                "description": null,
                "handler": "cmd_ls_project_list",
                "handler_doc": "Run the `dst ls project list` command handler and return a JSON-serializable result.",
                "positionals": [],
                "options": [
                  {
                    "option_strings": [
                      "--config"
                    ],
                    "dest": "config",
                    "required": false,
                    "default": null,
                    "help": "Path to local config JSON (otherwise DST_CONFIG_PATH, package-local file, or ~/.config/dst/local_config.json)",
                    "choices": null,
                    "metavar": null,
                    "nargs": null
                  },
                  {
                    "option_strings": [
                      "--overrides"
                    ],
                    "dest": "overrides",
                    "required": false,
                    "default": null,
                    "help": "JSON object with runtime config overrides",
                    "choices": null,
                    "metavar": null,
                    "nargs": null
                  },
                  {
                    "option_strings": [
                      "--contains"
                    ],
                    "dest": "contains",
                    "required": false,
                    "default": null,
                    "help": "Filter title by substring",
                    "choices": null,
                    "metavar": null,
                    "nargs": null
                  },
                  {
                    "option_strings": [
                      "--case-sensitive"
                    ],
                    "dest": "case_sensitive",
                    "required": false,
                    "default": false,
                    "help": null,
                    "choices": null,
                    "metavar": null,
                    "nargs": 0
                  },
                  {
                    "option_strings": [
                      "--limit"
                    ],
                    "dest": "limit",
                    "required": false,
                    "default": null,
                    "help": null,
                    "choices": null,
                    "metavar": null,
                    "nargs": null
                  },
                  {
                    "option_strings": [
                      "--with-task-count"
                    ],
                    "dest": "with_task_count",
                    "required": false,
                    "default": false,
                    "help": null,
                    "choices": null,
                    "metavar": null,
                    "nargs": 0
                  }
                ],
                "subcommands": {}
              },
              "clear-tasks": {
                "path": [
                  "ls",
                  "project",
                  "clear-tasks"
                ],
                "prog": "dst ls project clear-tasks",
                "description": null,
                "handler": "cmd_ls_project_clear_tasks",
                "handler_doc": "Run the `dst ls project clear tasks` command handler and return a JSON-serializable result.",
                "positionals": [],
                "options": [
                  {
                    "option_strings": [
                      "--config"
                    ],
                    "dest": "config",
                    "required": false,
                    "default": null,
                    "help": "Path to local config JSON (otherwise DST_CONFIG_PATH, package-local file, or ~/.config/dst/local_config.json)",
                    "choices": null,
                    "metavar": null,
                    "nargs": null
                  },
                  {
                    "option_strings": [
                      "--overrides"
                    ],
                    "dest": "overrides",
                    "required": false,
                    "default": null,
                    "help": "JSON object with runtime config overrides",
                    "choices": null,
                    "metavar": null,
                    "nargs": null
                  },
                  {
                    "option_strings": [
                      "--id"
                    ],
                    "dest": "id",
                    "required": false,
                    "default": null,
                    "help": "Project ID",
                    "choices": null,
                    "metavar": null,
                    "nargs": null
                  },
                  {
                    "option_strings": [
                      "--title"
                    ],
                    "dest": "title",
                    "required": false,
                    "default": null,
                    "help": "Project title (exact match)",
                    "choices": null,
                    "metavar": null,
                    "nargs": null
                  },
                  {
                    "option_strings": [
                      "--dry-run"
                    ],
                    "dest": "dry_run",
                    "required": false,
                    "default": false,
                    "help": null,
                    "choices": null,
                    "metavar": null,
                    "nargs": 0
                  }
                ],
                "subcommands": {}
              },
              "cleanup": {
                "path": [
                  "ls",
                  "project",
                  "cleanup"
                ],
                "prog": "dst ls project cleanup",
                "description": null,
                "handler": "cmd_ls_project_cleanup",
                "handler_doc": "Run the `dst ls project cleanup` command handler and return a JSON-serializable result.",
                "positionals": [],
                "options": [
                  {
                    "option_strings": [
                      "--config"
                    ],
                    "dest": "config",
                    "required": false,
                    "default": null,
                    "help": "Path to local config JSON (otherwise DST_CONFIG_PATH, package-local file, or ~/.config/dst/local_config.json)",
                    "choices": null,
                    "metavar": null,
                    "nargs": null
                  },
                  {
                    "option_strings": [
                      "--overrides"
                    ],
                    "dest": "overrides",
                    "required": false,
                    "default": null,
                    "help": "JSON object with runtime config overrides",
                    "choices": null,
                    "metavar": null,
                    "nargs": null
                  },
                  {
                    "option_strings": [
                      "--keyword"
                    ],
                    "dest": "keyword",
                    "required": true,
                    "default": null,
                    "help": "Keyword to match",
                    "choices": null,
                    "metavar": null,
                    "nargs": null
                  },
                  {
                    "option_strings": [
                      "--dry-run"
                    ],
                    "dest": "dry_run",
                    "required": false,
                    "default": false,
                    "help": null,
                    "choices": null,
                    "metavar": null,
                    "nargs": 0
                  },
                  {
                    "option_strings": [
                      "--case-sensitive"
                    ],
                    "dest": "case_sensitive",
                    "required": false,
                    "default": false,
                    "help": null,
                    "choices": null,
                    "metavar": null,
                    "nargs": 0
                  }
                ],
                "subcommands": {}
              }
            }
          }
        }
      },
      "data": {
        "path": [
          "data"
        ],
        "prog": "dst data",
        "description": null,
        "handler": null,
        "handler_doc": null,
        "positionals": [],
        "options": [],
        "subcommands": {
          "load": {
            "path": [
              "data",
              "load"
            ],
            "prog": "dst data load",
            "description": null,
            "handler": null,
            "handler_doc": null,
            "positionals": [],
            "options": [],
            "subcommands": {
              "yolo": {
                "path": [
                  "data",
                  "load",
                  "yolo"
                ],
                "prog": "dst data load yolo",
                "description": null,
                "handler": "cmd_data_load_yolo",
                "handler_doc": "Run the `dst data load yolo` command handler and return a JSON-serializable result.",
                "positionals": [],
                "options": [
                  {
                    "option_strings": [
                      "--config"
                    ],
                    "dest": "config",
                    "required": false,
                    "default": null,
                    "help": "Path to local config JSON (otherwise DST_CONFIG_PATH, package-local file, or ~/.config/dst/local_config.json)",
                    "choices": null,
                    "metavar": null,
                    "nargs": null
                  },
                  {
                    "option_strings": [
                      "--overrides"
                    ],
                    "dest": "overrides",
                    "required": false,
                    "default": null,
                    "help": "JSON object with runtime config overrides",
                    "choices": null,
                    "metavar": null,
                    "nargs": null
                  },
                  {
                    "option_strings": [
                      "--dataset"
                    ],
                    "dest": "dataset",
                    "required": false,
                    "default": null,
                    "help": "Target FiftyOne dataset name",
                    "choices": null,
                    "metavar": null,
                    "nargs": null
                  },
                  {
                    "option_strings": [
                      "--root"
                    ],
                    "dest": "root",
                    "required": false,
                    "default": null,
                    "help": "Root containing images/ and labels/",
                    "choices": null,
                    "metavar": null,
                    "nargs": null
                  },
                  {
                    "option_strings": [
                      "--images-root"
                    ],
                    "dest": "images_root",
                    "required": false,
                    "default": null,
                    "help": "Images root for mirrored layout",
                    "choices": null,
                    "metavar": null,
                    "nargs": null
                  },
                  {
                    "option_strings": [
                      "--labels-root"
                    ],
                    "dest": "labels_root",
                    "required": false,
                    "default": null,
                    "help": "Labels root for mirrored layout",
                    "choices": null,
                    "metavar": null,
                    "nargs": null
                  },
                  {
                    "option_strings": [
                      "--images-subdir"
                    ],
                    "dest": "images_subdir",
                    "required": false,
                    "default": "images",
                    "help": null,
                    "choices": null,
                    "metavar": null,
                    "nargs": null
                  },
                  {
                    "option_strings": [
                      "--labels-subdir"
                    ],
                    "dest": "labels_subdir",
                    "required": false,
                    "default": "labels",
                    "help": null,
                    "choices": null,
                    "metavar": null,
                    "nargs": null
                  },
                  {
                    "option_strings": [
                      "--class-map"
                    ],
                    "dest": "class_map",
                    "required": false,
                    "default": null,
                    "help": "JSON map like {\"0\":\"rodent\"}",
                    "choices": null,
                    "metavar": null,
                    "nargs": null
                  },
                  {
                    "option_strings": [
                      "--no-confidence"
                    ],
                    "dest": "no_confidence",
                    "required": false,
                    "default": false,
                    "help": "Ignore 6th YOLO confidence column",
                    "choices": null,
                    "metavar": null,
                    "nargs": 0
                  },
                  {
                    "option_strings": [
                      "--overwrite"
                    ],
                    "dest": "overwrite",
                    "required": false,
                    "default": false,
                    "help": null,
                    "choices": null,
                    "metavar": null,
                    "nargs": 0
                  },
                  {
                    "option_strings": [
                      "--persistent"
                    ],
                    "dest": "persistent",
                    "required": false,
                    "default": true,
                    "help": null,
                    "choices": null,
                    "metavar": null,
                    "nargs": 0
                  },
                  {
                    "option_strings": [
                      "--non-persistent"
                    ],
                    "dest": "persistent",
                    "required": false,
                    "default": true,
                    "help": null,
                    "choices": null,
                    "metavar": null,
                    "nargs": 0
                  }
                ],
                "subcommands": {}
              },
              "coco": {
                "path": [
                  "data",
                  "load",
                  "coco"
                ],
                "prog": "dst data load coco",
                "description": null,
                "handler": "cmd_data_load_coco",
                "handler_doc": "Run the `dst data load coco` command handler and return a JSON-serializable result.",
                "positionals": [],
                "options": [
                  {
                    "option_strings": [
                      "--config"
                    ],
                    "dest": "config",
                    "required": false,
                    "default": null,
                    "help": "Path to local config JSON (otherwise DST_CONFIG_PATH, package-local file, or ~/.config/dst/local_config.json)",
                    "choices": null,
                    "metavar": null,
                    "nargs": null
                  },
                  {
                    "option_strings": [
                      "--overrides"
                    ],
                    "dest": "overrides",
                    "required": false,
                    "default": null,
                    "help": "JSON object with runtime config overrides",
                    "choices": null,
                    "metavar": null,
                    "nargs": null
                  },
                  {
                    "option_strings": [
                      "--dataset"
                    ],
                    "dest": "dataset",
                    "required": false,
                    "default": null,
                    "help": "Target FiftyOne dataset name",
                    "choices": null,
                    "metavar": null,
                    "nargs": null
                  },
                  {
                    "option_strings": [
                      "--dataset-dir"
                    ],
                    "dest": "dataset_dir",
                    "required": true,
                    "default": null,
                    "help": null,
                    "choices": null,
                    "metavar": null,
                    "nargs": null
                  },
                  {
                    "option_strings": [
                      "--data-path"
                    ],
                    "dest": "data_path",
                    "required": false,
                    "default": "data",
                    "help": null,
                    "choices": null,
                    "metavar": null,
                    "nargs": null
                  },
                  {
                    "option_strings": [
                      "--labels-path"
                    ],
                    "dest": "labels_path",
                    "required": false,
                    "default": "labels.json",
                    "help": null,
                    "choices": null,
                    "metavar": null,
                    "nargs": null
                  },
                  {
                    "option_strings": [
                      "--overwrite"
                    ],
                    "dest": "overwrite",
                    "required": false,
                    "default": false,
                    "help": null,
                    "choices": null,
                    "metavar": null,
                    "nargs": 0
                  },
                  {
                    "option_strings": [
                      "--persistent"
                    ],
                    "dest": "persistent",
                    "required": false,
                    "default": true,
                    "help": null,
                    "choices": null,
                    "metavar": null,
                    "nargs": 0
                  },
                  {
                    "option_strings": [
                      "--non-persistent"
                    ],
                    "dest": "persistent",
                    "required": false,
                    "default": true,
                    "help": null,
                    "choices": null,
                    "metavar": null,
                    "nargs": 0
                  }
                ],
                "subcommands": {}
              }
            }
          },
          "export": {
            "path": [
              "data",
              "export"
            ],
            "prog": "dst data export",
            "description": null,
            "handler": null,
            "handler_doc": null,
            "positionals": [],
            "options": [],
            "subcommands": {
              "ls-json": {
                "path": [
                  "data",
                  "export",
                  "ls-json"
                ],
                "prog": "dst data export ls-json",
                "description": null,
                "handler": "cmd_data_export_ls_json",
                "handler_doc": "Run the `dst data export ls json` command handler and return a JSON-serializable result.",
                "positionals": [],
                "options": [
                  {
                    "option_strings": [
                      "--root"
                    ],
                    "dest": "root",
                    "required": true,
                    "default": null,
                    "help": "Root containing images/ and labels/",
                    "choices": null,
                    "metavar": null,
                    "nargs": null
                  },
                  {
                    "option_strings": [
                      "--ls-root"
                    ],
                    "dest": "ls_root",
                    "required": false,
                    "default": "/data/local-files/?d=frames_visitors_ndb/images",
                    "help": "Prefix used in generated task image URLs",
                    "choices": null,
                    "metavar": null,
                    "nargs": null
                  },
                  {
                    "option_strings": [
                      "--output"
                    ],
                    "dest": "output",
                    "required": false,
                    "default": null,
                    "help": "Output JSON path",
                    "choices": null,
                    "metavar": null,
                    "nargs": null
                  }
                ],
                "subcommands": {}
              }
            }
          }
        }
      },
      "metrics": {
        "path": [
          "metrics"
        ],
        "prog": "dst metrics",
        "description": null,
        "handler": null,
        "handler_doc": null,
        "positionals": [],
        "options": [],
        "subcommands": {
          "embeddings": {
            "path": [
              "metrics",
              "embeddings"
            ],
            "prog": "dst metrics embeddings",
            "description": null,
            "handler": "cmd_metrics_embeddings",
            "handler_doc": "Run the `dst metrics embeddings` command handler and return a JSON-serializable result.",
            "positionals": [],
            "options": [
              {
                "option_strings": [
                  "--dataset"
                ],
                "dest": "dataset",
                "required": true,
                "default": null,
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--model"
                ],
                "dest": "model",
                "required": false,
                "default": "facebook/dinov2-base",
                "help": "Legacy alias for HF model id when --model-ref is not provided",
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--model-ref"
                ],
                "dest": "model_ref",
                "required": false,
                "default": null,
                "help": "Provider-qualified model reference (e.g. hf:facebook/dinov2-base, foz:clip-vit-base32-torch)",
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--embeddings-field"
                ],
                "dest": "embeddings_field",
                "required": false,
                "default": "embeddings",
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--patches-field"
                ],
                "dest": "patches_field",
                "required": false,
                "default": null,
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--no-umap"
                ],
                "dest": "no_umap",
                "required": false,
                "default": false,
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": 0
              },
              {
                "option_strings": [
                  "--no-cluster"
                ],
                "dest": "no_cluster",
                "required": false,
                "default": false,
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": 0
              },
              {
                "option_strings": [
                  "--n-clusters"
                ],
                "dest": "n_clusters",
                "required": false,
                "default": 10,
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              }
            ],
            "subcommands": {}
          },
          "uniqueness": {
            "path": [
              "metrics",
              "uniqueness"
            ],
            "prog": "dst metrics uniqueness",
            "description": null,
            "handler": "cmd_metrics_uniqueness",
            "handler_doc": "Run the `dst metrics uniqueness` command handler and return a JSON-serializable result.",
            "positionals": [],
            "options": [
              {
                "option_strings": [
                  "--dataset"
                ],
                "dest": "dataset",
                "required": true,
                "default": null,
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--embeddings-field"
                ],
                "dest": "embeddings_field",
                "required": false,
                "default": null,
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--output-field"
                ],
                "dest": "output_field",
                "required": false,
                "default": "uniqueness",
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              }
            ],
            "subcommands": {}
          },
          "mistakenness": {
            "path": [
              "metrics",
              "mistakenness"
            ],
            "prog": "dst metrics mistakenness",
            "description": null,
            "handler": "cmd_metrics_mistakenness",
            "handler_doc": "Run the `dst metrics mistakenness` command handler and return a JSON-serializable result.",
            "positionals": [],
            "options": [
              {
                "option_strings": [
                  "--dataset"
                ],
                "dest": "dataset",
                "required": true,
                "default": null,
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--pred-field"
                ],
                "dest": "pred_field",
                "required": false,
                "default": "predictions",
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--gt-field"
                ],
                "dest": "gt_field",
                "required": false,
                "default": "ground_truth",
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--mistakenness-field"
                ],
                "dest": "mistakenness_field",
                "required": false,
                "default": "mistakenness",
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--missing-field"
                ],
                "dest": "missing_field",
                "required": false,
                "default": "possible_missing",
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--spurious-field"
                ],
                "dest": "spurious_field",
                "required": false,
                "default": "possible_spurious",
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              }
            ],
            "subcommands": {}
          },
          "hardness": {
            "path": [
              "metrics",
              "hardness"
            ],
            "prog": "dst metrics hardness",
            "description": null,
            "handler": "cmd_metrics_hardness",
            "handler_doc": "Run the `dst metrics hardness` command handler and return a JSON-serializable result.",
            "positionals": [],
            "options": [
              {
                "option_strings": [
                  "--dataset"
                ],
                "dest": "dataset",
                "required": true,
                "default": null,
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--label-field"
                ],
                "dest": "label_field",
                "required": false,
                "default": "ground_truth",
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--output-field"
                ],
                "dest": "output_field",
                "required": false,
                "default": "hardness",
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              }
            ],
            "subcommands": {}
          },
          "representativeness": {
            "path": [
              "metrics",
              "representativeness"
            ],
            "prog": "dst metrics representativeness",
            "description": null,
            "handler": "cmd_metrics_representativeness",
            "handler_doc": "Run the `dst metrics representativeness` command handler and return a JSON-serializable result.",
            "positionals": [],
            "options": [
              {
                "option_strings": [
                  "--dataset"
                ],
                "dest": "dataset",
                "required": true,
                "default": null,
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--output-field"
                ],
                "dest": "output_field",
                "required": false,
                "default": "representativeness",
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--method"
                ],
                "dest": "method",
                "required": false,
                "default": "cluster-center",
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--embeddings-field"
                ],
                "dest": "embeddings_field",
                "required": false,
                "default": null,
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--roi-field"
                ],
                "dest": "roi_field",
                "required": false,
                "default": null,
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              }
            ],
            "subcommands": {}
          }
        }
      },
      "brain": {
        "path": [
          "brain"
        ],
        "prog": "dst brain",
        "description": null,
        "handler": null,
        "handler_doc": null,
        "positionals": [],
        "options": [],
        "subcommands": {
          "visualization": {
            "path": [
              "brain",
              "visualization"
            ],
            "prog": "dst brain visualization",
            "description": null,
            "handler": "cmd_brain_visualization",
            "handler_doc": "Run the `dst brain visualization` command handler and return a JSON-serializable result.",
            "positionals": [],
            "options": [
              {
                "option_strings": [
                  "--dataset"
                ],
                "dest": "dataset",
                "required": true,
                "default": null,
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--method"
                ],
                "dest": "method",
                "required": false,
                "default": "umap",
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--num-dims"
                ],
                "dest": "num_dims",
                "required": false,
                "default": 2,
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--embeddings-field"
                ],
                "dest": "embeddings_field",
                "required": false,
                "default": null,
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--patches-field"
                ],
                "dest": "patches_field",
                "required": false,
                "default": null,
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--brain-key"
                ],
                "dest": "brain_key",
                "required": false,
                "default": null,
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              }
            ],
            "subcommands": {}
          },
          "similarity": {
            "path": [
              "brain",
              "similarity"
            ],
            "prog": "dst brain similarity",
            "description": null,
            "handler": "cmd_brain_similarity",
            "handler_doc": "Run the `dst brain similarity` command handler and return a JSON-serializable result.",
            "positionals": [],
            "options": [
              {
                "option_strings": [
                  "--dataset"
                ],
                "dest": "dataset",
                "required": true,
                "default": null,
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--embeddings-field"
                ],
                "dest": "embeddings_field",
                "required": false,
                "default": null,
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--patches-field"
                ],
                "dest": "patches_field",
                "required": false,
                "default": null,
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--roi-field"
                ],
                "dest": "roi_field",
                "required": false,
                "default": null,
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--backend"
                ],
                "dest": "backend",
                "required": false,
                "default": null,
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--brain-key"
                ],
                "dest": "brain_key",
                "required": false,
                "default": null,
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              }
            ],
            "subcommands": {}
          },
          "duplicates": {
            "path": [
              "brain",
              "duplicates"
            ],
            "prog": "dst brain duplicates",
            "description": null,
            "handler": null,
            "handler_doc": null,
            "positionals": [],
            "options": [],
            "subcommands": {
              "exact": {
                "path": [
                  "brain",
                  "duplicates",
                  "exact"
                ],
                "prog": "dst brain duplicates exact",
                "description": null,
                "handler": "cmd_brain_duplicates_exact",
                "handler_doc": "Run the `dst brain duplicates exact` command handler and return a JSON-serializable result.",
                "positionals": [],
                "options": [
                  {
                    "option_strings": [
                      "--dataset"
                    ],
                    "dest": "dataset",
                    "required": true,
                    "default": null,
                    "help": null,
                    "choices": null,
                    "metavar": null,
                    "nargs": null
                  }
                ],
                "subcommands": {}
              },
              "near": {
                "path": [
                  "brain",
                  "duplicates",
                  "near"
                ],
                "prog": "dst brain duplicates near",
                "description": null,
                "handler": "cmd_brain_duplicates_near",
                "handler_doc": "Run the `dst brain duplicates near` command handler and return a JSON-serializable result.",
                "positionals": [],
                "options": [
                  {
                    "option_strings": [
                      "--dataset"
                    ],
                    "dest": "dataset",
                    "required": true,
                    "default": null,
                    "help": null,
                    "choices": null,
                    "metavar": null,
                    "nargs": null
                  },
                  {
                    "option_strings": [
                      "--threshold"
                    ],
                    "dest": "threshold",
                    "required": false,
                    "default": 0.2,
                    "help": null,
                    "choices": null,
                    "metavar": null,
                    "nargs": null
                  },
                  {
                    "option_strings": [
                      "--embeddings-field"
                    ],
                    "dest": "embeddings_field",
                    "required": false,
                    "default": null,
                    "help": null,
                    "choices": null,
                    "metavar": null,
                    "nargs": null
                  },
                  {
                    "option_strings": [
                      "--roi-field"
                    ],
                    "dest": "roi_field",
                    "required": false,
                    "default": null,
                    "help": null,
                    "choices": null,
                    "metavar": null,
                    "nargs": null
                  }
                ],
                "subcommands": {}
              }
            }
          },
          "leaky-splits": {
            "path": [
              "brain",
              "leaky-splits"
            ],
            "prog": "dst brain leaky-splits",
            "description": null,
            "handler": "cmd_brain_leaky_splits",
            "handler_doc": "Run the `dst brain leaky splits` command handler and return a JSON-serializable result.",
            "positionals": [],
            "options": [
              {
                "option_strings": [
                  "--dataset"
                ],
                "dest": "dataset",
                "required": true,
                "default": null,
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--splits"
                ],
                "dest": "splits",
                "required": true,
                "default": null,
                "help": "Comma-separated split tags/values, e.g. train,val,test",
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--threshold"
                ],
                "dest": "threshold",
                "required": false,
                "default": 0.2,
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--embeddings-field"
                ],
                "dest": "embeddings_field",
                "required": false,
                "default": null,
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--roi-field"
                ],
                "dest": "roi_field",
                "required": false,
                "default": null,
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              }
            ],
            "subcommands": {}
          }
        }
      },
      "models": {
        "path": [
          "models"
        ],
        "prog": "dst models",
        "description": null,
        "handler": null,
        "handler_doc": null,
        "positionals": [],
        "options": [],
        "subcommands": {
          "list": {
            "path": [
              "models",
              "list"
            ],
            "prog": "dst models list",
            "description": null,
            "handler": "cmd_models_list",
            "handler_doc": "Run the `dst models list` command handler and return a JSON-serializable result.",
            "positionals": [],
            "options": [
              {
                "option_strings": [
                  "--provider"
                ],
                "dest": "provider",
                "required": false,
                "default": null,
                "help": "Provider name. If omitted, lists available providers.",
                "choices": [
                  "hf",
                  "foz",
                  "anomalib"
                ],
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--contains"
                ],
                "dest": "contains",
                "required": false,
                "default": null,
                "help": "Optional substring filter",
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--limit"
                ],
                "dest": "limit",
                "required": false,
                "default": 50,
                "help": "Max models to return",
                "choices": null,
                "metavar": null,
                "nargs": null
              }
            ],
            "subcommands": {}
          },
          "resolve": {
            "path": [
              "models",
              "resolve"
            ],
            "prog": "dst models resolve",
            "description": null,
            "handler": "cmd_models_resolve",
            "handler_doc": "Run the `dst models resolve` command handler and return a JSON-serializable result.",
            "positionals": [],
            "options": [
              {
                "option_strings": [
                  "--model-ref"
                ],
                "dest": "model_ref",
                "required": true,
                "default": null,
                "help": "Provider-qualified model ref",
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--default-provider"
                ],
                "dest": "default_provider",
                "required": false,
                "default": "hf",
                "help": "Provider used when --model-ref omits prefix",
                "choices": [
                  "hf",
                  "foz",
                  "anomalib"
                ],
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--task"
                ],
                "dest": "task",
                "required": false,
                "default": null,
                "help": "Optional task hint (e.g. embeddings, anomaly)",
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--capability"
                ],
                "dest": "capability",
                "required": false,
                "default": null,
                "help": "Required capability (e.g. embeddings, anomaly)",
                "choices": null,
                "metavar": null,
                "nargs": null
              }
            ],
            "subcommands": {}
          },
          "validate": {
            "path": [
              "models",
              "validate"
            ],
            "prog": "dst models validate",
            "description": null,
            "handler": "cmd_models_validate",
            "handler_doc": "Run the `dst models validate` command handler and return a JSON-serializable result.",
            "positionals": [],
            "options": [
              {
                "option_strings": [
                  "--model-ref"
                ],
                "dest": "model_ref",
                "required": true,
                "default": null,
                "help": "Provider-qualified model ref",
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--default-provider"
                ],
                "dest": "default_provider",
                "required": false,
                "default": "hf",
                "help": "Provider used when --model-ref omits prefix",
                "choices": [
                  "hf",
                  "foz",
                  "anomalib"
                ],
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--task"
                ],
                "dest": "task",
                "required": false,
                "default": null,
                "help": "Optional task hint",
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--capability"
                ],
                "dest": "capability",
                "required": false,
                "default": null,
                "help": "Required capability",
                "choices": null,
                "metavar": null,
                "nargs": null
              }
            ],
            "subcommands": {}
          }
        }
      },
      "anomaly": {
        "path": [
          "anomaly"
        ],
        "prog": "dst anomaly",
        "description": null,
        "handler": null,
        "handler_doc": null,
        "positionals": [],
        "options": [],
        "subcommands": {
          "fit": {
            "path": [
              "anomaly",
              "fit"
            ],
            "prog": "dst anomaly fit",
            "description": null,
            "handler": "cmd_anomaly_fit",
            "handler_doc": "Run the `dst anomaly fit` command handler and return a JSON-serializable result.",
            "positionals": [],
            "options": [
              {
                "option_strings": [
                  "--dataset"
                ],
                "dest": "dataset",
                "required": true,
                "default": null,
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--backend"
                ],
                "dest": "backend",
                "required": false,
                "default": "embedding_distance",
                "help": null,
                "choices": [
                  "embedding_distance",
                  "anomalib"
                ],
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--embeddings-field"
                ],
                "dest": "embeddings_field",
                "required": false,
                "default": "embeddings",
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--normal-tag"
                ],
                "dest": "normal_tag",
                "required": false,
                "default": null,
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--threshold"
                ],
                "dest": "threshold",
                "required": false,
                "default": null,
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--threshold-quantile"
                ],
                "dest": "threshold_quantile",
                "required": false,
                "default": 0.95,
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--reference-json"
                ],
                "dest": "reference_json",
                "required": false,
                "default": null,
                "help": "Optional path to persist fitted reference",
                "choices": null,
                "metavar": null,
                "nargs": null
              }
            ],
            "subcommands": {}
          },
          "train": {
            "path": [
              "anomaly",
              "train"
            ],
            "prog": "dst anomaly train",
            "description": null,
            "handler": "cmd_anomaly_train",
            "handler_doc": "Run the `dst anomaly train` command handler and return a JSON-serializable result.",
            "positionals": [],
            "options": [
              {
                "option_strings": [
                  "--dataset"
                ],
                "dest": "dataset",
                "required": true,
                "default": null,
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--model-ref"
                ],
                "dest": "model_ref",
                "required": false,
                "default": "anomalib:padim",
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--normal-tag"
                ],
                "dest": "normal_tag",
                "required": false,
                "default": null,
                "help": "Tag selecting normal samples for training",
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--abnormal-tag"
                ],
                "dest": "abnormal_tag",
                "required": false,
                "default": null,
                "help": "Optional tag selecting abnormal samples",
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--mask-field"
                ],
                "dest": "mask_field",
                "required": false,
                "default": null,
                "help": "Optional mask field for abnormal samples",
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--artifact-dir"
                ],
                "dest": "artifact_dir",
                "required": false,
                "default": null,
                "help": "Directory where trained artifact is stored",
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--data-dir"
                ],
                "dest": "data_dir",
                "required": false,
                "default": null,
                "help": "Directory for generated anomalib Folder data",
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--artifact-format"
                ],
                "dest": "artifact_format",
                "required": false,
                "default": "openvino",
                "help": null,
                "choices": [
                  "openvino",
                  "torch"
                ],
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--artifact-json"
                ],
                "dest": "artifact_json",
                "required": false,
                "default": null,
                "help": "Optional explicit output path for artifact JSON",
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--image-size"
                ],
                "dest": "image_size",
                "required": false,
                "default": null,
                "help": "Image size: N or W,H for resize pre-processing",
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--train-batch-size"
                ],
                "dest": "train_batch_size",
                "required": false,
                "default": 8,
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--eval-batch-size"
                ],
                "dest": "eval_batch_size",
                "required": false,
                "default": 8,
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--num-workers"
                ],
                "dest": "num_workers",
                "required": false,
                "default": 0,
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--normal-split-ratio"
                ],
                "dest": "normal_split_ratio",
                "required": false,
                "default": 0.2,
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--test-split-mode"
                ],
                "dest": "test_split_mode",
                "required": false,
                "default": "from_dir",
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--test-split-ratio"
                ],
                "dest": "test_split_ratio",
                "required": false,
                "default": 0.2,
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--val-split-mode"
                ],
                "dest": "val_split_mode",
                "required": false,
                "default": "same_as_test",
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--val-split-ratio"
                ],
                "dest": "val_split_ratio",
                "required": false,
                "default": 0.5,
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--seed"
                ],
                "dest": "seed",
                "required": false,
                "default": null,
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--max-epochs"
                ],
                "dest": "max_epochs",
                "required": false,
                "default": null,
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--accelerator"
                ],
                "dest": "accelerator",
                "required": false,
                "default": null,
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--devices"
                ],
                "dest": "devices",
                "required": false,
                "default": null,
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--copy-media"
                ],
                "dest": "copy_media",
                "required": false,
                "default": false,
                "help": "Copy files instead of symlinking",
                "choices": null,
                "metavar": null,
                "nargs": 0
              },
              {
                "option_strings": [
                  "--overwrite-data"
                ],
                "dest": "overwrite_data",
                "required": false,
                "default": false,
                "help": "Replace existing generated training data directory",
                "choices": null,
                "metavar": null,
                "nargs": 0
              }
            ],
            "subcommands": {}
          },
          "score": {
            "path": [
              "anomaly",
              "score"
            ],
            "prog": "dst anomaly score",
            "description": null,
            "handler": "cmd_anomaly_score",
            "handler_doc": "Run the `dst anomaly score` command handler and return a JSON-serializable result.",
            "positionals": [],
            "options": [
              {
                "option_strings": [
                  "--dataset"
                ],
                "dest": "dataset",
                "required": true,
                "default": null,
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--backend"
                ],
                "dest": "backend",
                "required": false,
                "default": "embedding_distance",
                "help": null,
                "choices": [
                  "embedding_distance",
                  "anomalib"
                ],
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--embeddings-field"
                ],
                "dest": "embeddings_field",
                "required": false,
                "default": "embeddings",
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--normal-tag"
                ],
                "dest": "normal_tag",
                "required": false,
                "default": null,
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--threshold"
                ],
                "dest": "threshold",
                "required": false,
                "default": null,
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--threshold-quantile"
                ],
                "dest": "threshold_quantile",
                "required": false,
                "default": 0.95,
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--reference-json"
                ],
                "dest": "reference_json",
                "required": false,
                "default": null,
                "help": "Optional path to fitted reference JSON",
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--model-ref"
                ],
                "dest": "model_ref",
                "required": false,
                "default": "anomalib:padim",
                "help": "Deprecated for backend=anomalib; use --artifact",
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--artifact"
                ],
                "dest": "artifact",
                "required": false,
                "default": null,
                "help": "Path to anomalib artifact JSON or exported model file",
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--artifact-format"
                ],
                "dest": "artifact_format",
                "required": false,
                "default": null,
                "help": null,
                "choices": [
                  "openvino",
                  "torch"
                ],
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--anomaly-threshold"
                ],
                "dest": "anomaly_threshold",
                "required": false,
                "default": 0.5,
                "help": "Threshold for anomaly flag/label",
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--device"
                ],
                "dest": "device",
                "required": false,
                "default": null,
                "help": "Inference device for anomalib backend",
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--trust-remote-code"
                ],
                "dest": "trust_remote_code",
                "required": false,
                "default": false,
                "help": "Allow loading torch anomalib artifacts via pickle (only for trusted artifacts)",
                "choices": null,
                "metavar": null,
                "nargs": 0
              },
              {
                "option_strings": [
                  "--tag"
                ],
                "dest": "tag",
                "required": false,
                "default": null,
                "help": "Optional sample tag filter for scoring",
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--score-field"
                ],
                "dest": "score_field",
                "required": false,
                "default": "anomaly_score",
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--flag-field"
                ],
                "dest": "flag_field",
                "required": false,
                "default": "is_anomaly",
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--label-field"
                ],
                "dest": "label_field",
                "required": false,
                "default": null,
                "help": "Optional Classification output field",
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--map-field"
                ],
                "dest": "map_field",
                "required": false,
                "default": null,
                "help": "Optional Heatmap output field",
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--mask-field"
                ],
                "dest": "mask_field",
                "required": false,
                "default": null,
                "help": "Optional Segmentation output field",
                "choices": null,
                "metavar": null,
                "nargs": null
              }
            ],
            "subcommands": {}
          },
          "run": {
            "path": [
              "anomaly",
              "run"
            ],
            "prog": "dst anomaly run",
            "description": null,
            "handler": "cmd_anomaly_run",
            "handler_doc": "Run the `dst anomaly run` command handler and return a JSON-serializable result.",
            "positionals": [],
            "options": [
              {
                "option_strings": [
                  "--dataset"
                ],
                "dest": "dataset",
                "required": true,
                "default": null,
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--backend"
                ],
                "dest": "backend",
                "required": false,
                "default": "embedding_distance",
                "help": null,
                "choices": [
                  "embedding_distance",
                  "anomalib"
                ],
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--embeddings-field"
                ],
                "dest": "embeddings_field",
                "required": false,
                "default": "embeddings",
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--normal-tag"
                ],
                "dest": "normal_tag",
                "required": false,
                "default": null,
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--threshold"
                ],
                "dest": "threshold",
                "required": false,
                "default": null,
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--threshold-quantile"
                ],
                "dest": "threshold_quantile",
                "required": false,
                "default": 0.95,
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--reference-json"
                ],
                "dest": "reference_json",
                "required": false,
                "default": null,
                "help": "Optional path to persist fitted reference",
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--model-ref"
                ],
                "dest": "model_ref",
                "required": false,
                "default": "anomalib:padim",
                "help": "Deprecated for backend=anomalib; use --artifact",
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--artifact"
                ],
                "dest": "artifact",
                "required": false,
                "default": null,
                "help": "Path to anomalib artifact JSON or exported model file",
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--artifact-format"
                ],
                "dest": "artifact_format",
                "required": false,
                "default": null,
                "help": null,
                "choices": [
                  "openvino",
                  "torch"
                ],
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--anomaly-threshold"
                ],
                "dest": "anomaly_threshold",
                "required": false,
                "default": 0.5,
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--device"
                ],
                "dest": "device",
                "required": false,
                "default": null,
                "help": "Inference device for anomalib backend",
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--trust-remote-code"
                ],
                "dest": "trust_remote_code",
                "required": false,
                "default": false,
                "help": "Allow loading torch anomalib artifacts via pickle (only for trusted artifacts)",
                "choices": null,
                "metavar": null,
                "nargs": 0
              },
              {
                "option_strings": [
                  "--tag"
                ],
                "dest": "tag",
                "required": false,
                "default": null,
                "help": "Optional sample tag filter for scoring",
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--score-field"
                ],
                "dest": "score_field",
                "required": false,
                "default": "anomaly_score",
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--flag-field"
                ],
                "dest": "flag_field",
                "required": false,
                "default": "is_anomaly",
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--label-field"
                ],
                "dest": "label_field",
                "required": false,
                "default": null,
                "help": "Optional Classification output field",
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--map-field"
                ],
                "dest": "map_field",
                "required": false,
                "default": null,
                "help": "Optional Heatmap output field",
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--mask-field"
                ],
                "dest": "mask_field",
                "required": false,
                "default": null,
                "help": "Optional Segmentation output field",
                "choices": null,
                "metavar": null,
                "nargs": null
              }
            ],
            "subcommands": {}
          }
        }
      },
      "workflow": {
        "path": [
          "workflow"
        ],
        "prog": "dst workflow",
        "description": null,
        "handler": null,
        "handler_doc": null,
        "positionals": [],
        "options": [],
        "subcommands": {
          "roundtrip": {
            "path": [
              "workflow",
              "roundtrip"
            ],
            "prog": "dst workflow roundtrip",
            "description": null,
            "handler": "cmd_workflow_roundtrip",
            "handler_doc": "Run the `dst workflow roundtrip` command handler and return a JSON-serializable result.",
            "positionals": [],
            "options": [
              {
                "option_strings": [
                  "--config"
                ],
                "dest": "config",
                "required": false,
                "default": null,
                "help": "Path to local config JSON (otherwise DST_CONFIG_PATH, package-local file, or ~/.config/dst/local_config.json)",
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--overrides"
                ],
                "dest": "overrides",
                "required": false,
                "default": null,
                "help": "JSON object with runtime config overrides",
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--dataset"
                ],
                "dest": "dataset",
                "required": true,
                "default": null,
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--tag"
                ],
                "dest": "tag",
                "required": false,
                "default": "fix",
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--project"
                ],
                "dest": "project",
                "required": false,
                "default": null,
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--label-field"
                ],
                "dest": "label_field",
                "required": false,
                "default": "ground_truth",
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--corrections-field"
                ],
                "dest": "corrections_field",
                "required": false,
                "default": "ls_corrections",
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--skip-send"
                ],
                "dest": "skip_send",
                "required": false,
                "default": false,
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": 0
              },
              {
                "option_strings": [
                  "--skip-pull"
                ],
                "dest": "skip_pull",
                "required": false,
                "default": false,
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": 0
              },
              {
                "option_strings": [
                  "--skip-sync-disk"
                ],
                "dest": "skip_sync_disk",
                "required": false,
                "default": false,
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": 0
              },
              {
                "option_strings": [
                  "--dry-run-sync"
                ],
                "dest": "dry_run_sync",
                "required": false,
                "default": false,
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": 0
              },
              {
                "option_strings": [
                  "--clear-project-tasks"
                ],
                "dest": "clear_project_tasks",
                "required": false,
                "default": false,
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": 0
              },
              {
                "option_strings": [
                  "--upload-strategy"
                ],
                "dest": "upload_strategy",
                "required": false,
                "default": null,
                "help": null,
                "choices": [
                  "annotate_batched",
                  "sdk_batched"
                ],
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--pull-strategy"
                ],
                "dest": "pull_strategy",
                "required": false,
                "default": null,
                "help": null,
                "choices": [
                  "sdk_meta",
                  "annotate_run"
                ],
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--annotation-key"
                ],
                "dest": "annotation_key",
                "required": false,
                "default": null,
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--launch-editor"
                ],
                "dest": "launch_editor",
                "required": false,
                "default": false,
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": 0
              },
              {
                "option_strings": [
                  "--create-if-missing"
                ],
                "dest": "create_if_missing",
                "required": false,
                "default": false,
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": 0
              },
              {
                "option_strings": [
                  "--strict-preflight"
                ],
                "dest": "strict_preflight",
                "required": false,
                "default": true,
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": 0
              },
              {
                "option_strings": [
                  "--no-strict-preflight"
                ],
                "dest": "strict_preflight",
                "required": false,
                "default": true,
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": 0
              },
              {
                "option_strings": [
                  "--overwrite-annotation-run"
                ],
                "dest": "overwrite_annotation_run",
                "required": false,
                "default": true,
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": 0
              },
              {
                "option_strings": [
                  "--no-overwrite-annotation-run"
                ],
                "dest": "overwrite_annotation_run",
                "required": false,
                "default": true,
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": 0
              },
              {
                "option_strings": [
                  "--send-params"
                ],
                "dest": "send_params",
                "required": false,
                "default": null,
                "help": "JSON object merged into send params",
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--pull-params"
                ],
                "dest": "pull_params",
                "required": false,
                "default": null,
                "help": "JSON object merged into pull params",
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--sync-params"
                ],
                "dest": "sync_params",
                "required": false,
                "default": null,
                "help": "JSON object merged into sync params",
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--quiet-logs"
                ],
                "dest": "quiet_logs",
                "required": false,
                "default": false,
                "help": "Suppress noisy stdout/stderr logs from underlying workflow operations",
                "choices": null,
                "metavar": null,
                "nargs": 0
              },
              {
                "option_strings": [
                  "--output-json"
                ],
                "dest": "output_json",
                "required": false,
                "default": null,
                "help": "Write workflow result payload to a JSON file",
                "choices": null,
                "metavar": null,
                "nargs": null
              }
            ],
            "subcommands": {}
          },
          "tags": {
            "path": [
              "workflow",
              "tags"
            ],
            "prog": "dst workflow tags",
            "description": null,
            "handler": null,
            "handler_doc": null,
            "positionals": [],
            "options": [],
            "subcommands": {
              "run": {
                "path": [
                  "workflow",
                  "tags",
                  "run"
                ],
                "prog": "dst workflow tags run",
                "description": null,
                "handler": "cmd_workflow_tags_run",
                "handler_doc": "Run the `dst workflow tags run` command handler and return a JSON-serializable result.",
                "positionals": [],
                "options": [
                  {
                    "option_strings": [
                      "--config"
                    ],
                    "dest": "config",
                    "required": false,
                    "default": null,
                    "help": "Path to local config JSON (otherwise DST_CONFIG_PATH, package-local file, or ~/.config/dst/local_config.json)",
                    "choices": null,
                    "metavar": null,
                    "nargs": null
                  },
                  {
                    "option_strings": [
                      "--overrides"
                    ],
                    "dest": "overrides",
                    "required": false,
                    "default": null,
                    "help": "JSON object with runtime config overrides",
                    "choices": null,
                    "metavar": null,
                    "nargs": null
                  },
                  {
                    "option_strings": [
                      "--workflow"
                    ],
                    "dest": "workflow",
                    "required": true,
                    "default": null,
                    "help": null,
                    "choices": null,
                    "metavar": null,
                    "nargs": null
                  },
                  {
                    "option_strings": [
                      "--dataset"
                    ],
                    "dest": "dataset",
                    "required": false,
                    "default": null,
                    "help": "Override dataset_name from workflow file",
                    "choices": null,
                    "metavar": null,
                    "nargs": null
                  },
                  {
                    "option_strings": [
                      "--fail-fast"
                    ],
                    "dest": "fail_fast",
                    "required": false,
                    "default": null,
                    "help": null,
                    "choices": null,
                    "metavar": null,
                    "nargs": 0
                  },
                  {
                    "option_strings": [
                      "--no-fail-fast"
                    ],
                    "dest": "fail_fast",
                    "required": false,
                    "default": true,
                    "help": null,
                    "choices": null,
                    "metavar": null,
                    "nargs": 0
                  },
                  {
                    "option_strings": [
                      "--quiet-logs"
                    ],
                    "dest": "quiet_logs",
                    "required": false,
                    "default": false,
                    "help": "Suppress noisy stdout/stderr logs from underlying workflow operations",
                    "choices": null,
                    "metavar": null,
                    "nargs": 0
                  },
                  {
                    "option_strings": [
                      "--output-json"
                    ],
                    "dest": "output_json",
                    "required": false,
                    "default": null,
                    "help": "Write workflow result payload to a JSON file",
                    "choices": null,
                    "metavar": null,
                    "nargs": null
                  }
                ],
                "subcommands": {}
              },
              "inline": {
                "path": [
                  "workflow",
                  "tags",
                  "inline"
                ],
                "prog": "dst workflow tags inline",
                "description": null,
                "handler": "cmd_workflow_tags_inline",
                "handler_doc": "Run the `dst workflow tags inline` command handler and return a JSON-serializable result.",
                "positionals": [],
                "options": [
                  {
                    "option_strings": [
                      "--config"
                    ],
                    "dest": "config",
                    "required": false,
                    "default": null,
                    "help": "Path to local config JSON (otherwise DST_CONFIG_PATH, package-local file, or ~/.config/dst/local_config.json)",
                    "choices": null,
                    "metavar": null,
                    "nargs": null
                  },
                  {
                    "option_strings": [
                      "--overrides"
                    ],
                    "dest": "overrides",
                    "required": false,
                    "default": null,
                    "help": "JSON object with runtime config overrides",
                    "choices": null,
                    "metavar": null,
                    "nargs": null
                  },
                  {
                    "option_strings": [
                      "--dataset"
                    ],
                    "dest": "dataset",
                    "required": true,
                    "default": null,
                    "help": null,
                    "choices": null,
                    "metavar": null,
                    "nargs": null
                  },
                  {
                    "option_strings": [
                      "--rule"
                    ],
                    "dest": "rule",
                    "required": true,
                    "default": null,
                    "help": "JSON object, e.g. {\"tag\":\"delete\",\"operation\":\"delete_samples\"}",
                    "choices": null,
                    "metavar": null,
                    "nargs": null
                  },
                  {
                    "option_strings": [
                      "--no-fail-fast"
                    ],
                    "dest": "no_fail_fast",
                    "required": false,
                    "default": false,
                    "help": null,
                    "choices": null,
                    "metavar": null,
                    "nargs": 0
                  },
                  {
                    "option_strings": [
                      "--quiet-logs"
                    ],
                    "dest": "quiet_logs",
                    "required": false,
                    "default": false,
                    "help": "Suppress noisy stdout/stderr logs from underlying workflow operations",
                    "choices": null,
                    "metavar": null,
                    "nargs": 0
                  },
                  {
                    "option_strings": [
                      "--output-json"
                    ],
                    "dest": "output_json",
                    "required": false,
                    "default": null,
                    "help": "Write workflow result payload to a JSON file",
                    "choices": null,
                    "metavar": null,
                    "nargs": null
                  }
                ],
                "subcommands": {}
              }
            }
          }
        }
      },
      "sync": {
        "path": [
          "sync"
        ],
        "prog": "dst sync",
        "description": null,
        "handler": null,
        "handler_doc": null,
        "positionals": [],
        "options": [],
        "subcommands": {
          "disk": {
            "path": [
              "sync",
              "disk"
            ],
            "prog": "dst sync disk",
            "description": null,
            "handler": "cmd_sync_disk",
            "handler_doc": "Run the `dst sync disk` command handler and return a JSON-serializable result.",
            "positionals": [],
            "options": [
              {
                "option_strings": [
                  "--config"
                ],
                "dest": "config",
                "required": false,
                "default": null,
                "help": "Path to local config JSON (otherwise DST_CONFIG_PATH, package-local file, or ~/.config/dst/local_config.json)",
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--overrides"
                ],
                "dest": "overrides",
                "required": false,
                "default": null,
                "help": "JSON object with runtime config overrides",
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--dataset"
                ],
                "dest": "dataset",
                "required": false,
                "default": null,
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--tag"
                ],
                "dest": "tag",
                "required": false,
                "default": null,
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--dry-run"
                ],
                "dest": "dry_run",
                "required": false,
                "default": false,
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": 0
              },
              {
                "option_strings": [
                  "--corrections-field"
                ],
                "dest": "corrections_field",
                "required": false,
                "default": null,
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--label-to-class-id"
                ],
                "dest": "label_to_class_id",
                "required": false,
                "default": null,
                "help": "JSON object e.g. {\"rodent\":0}",
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--default-class-id"
                ],
                "dest": "default_class_id",
                "required": false,
                "default": null,
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--path-replacement"
                ],
                "dest": "path_replacement",
                "required": false,
                "default": null,
                "help": "Replacement rule SRC=DST, can be repeated",
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--backup-suffix-format"
                ],
                "dest": "backup_suffix_format",
                "required": false,
                "default": null,
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              }
            ],
            "subcommands": {}
          }
        }
      },
      "app": {
        "path": [
          "app"
        ],
        "prog": "dst app",
        "description": null,
        "handler": null,
        "handler_doc": null,
        "positionals": [],
        "options": [],
        "subcommands": {
          "open": {
            "path": [
              "app",
              "open"
            ],
            "prog": "dst app open",
            "description": null,
            "handler": "cmd_app_open",
            "handler_doc": "Run the `dst app open` command handler and return a JSON-serializable result.",
            "positionals": [],
            "options": [
              {
                "option_strings": [
                  "--dataset"
                ],
                "dest": "dataset",
                "required": true,
                "default": null,
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--port"
                ],
                "dest": "port",
                "required": false,
                "default": 5151,
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--address"
                ],
                "dest": "address",
                "required": false,
                "default": "0.0.0.0",
                "help": null,
                "choices": null,
                "metavar": null,
                "nargs": null
              },
              {
                "option_strings": [
                  "--no-block"
                ],
                "dest": "no_block",
                "required": false,
                "default": false,
                "help": "Launch app and return immediately",
                "choices": null,
                "metavar": null,
                "nargs": 0
              }
            ],
            "subcommands": {}
          }
        }
      }
    }
  }
}